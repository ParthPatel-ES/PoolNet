{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet_Quant.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XxT3dQQuuaOW",
        "_iBYkM4tulos",
        "rpMb7sA5XvyB",
        "Su0KeX0HwSOH",
        "cS6RPb51whj1",
        "dKuOLvQyur63",
        "FeBSPU79qeQa",
        "osq8VHox8SLI",
        "EJgqrdkXkGud"
      ],
      "toc_visible": true,
      "mount_file_id": "1VU-iRrWxM5HZHXfViWHfUhtIKdLEDB8X",
      "authorship_tag": "ABX9TyMIDhfjscvkWlLsMbsgdHMV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "371ccd5f898f4f309a4df5f942748de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_654007f5de0c4bcdb6c59f19bb72939a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0b67cd760a7f42038299b0d30377e8b2",
              "IPY_MODEL_f04776ca19d645f3b66cc2884f4a1f21"
            ]
          }
        },
        "654007f5de0c4bcdb6c59f19bb72939a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b67cd760a7f42038299b0d30377e8b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7c7ee7239c6d46e694299b1323af9182",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5b2c759e8961470c8361168b4d408fb5"
          }
        },
        "f04776ca19d645f3b66cc2884f4a1f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f4e0233d03fe4bb185b0f90fd720fa65",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:22&lt;00:00, 24.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09fa8e467ac9448a9508065693799d80"
          }
        },
        "7c7ee7239c6d46e694299b1323af9182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5b2c759e8961470c8361168b4d408fb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f4e0233d03fe4bb185b0f90fd720fa65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09fa8e467ac9448a9508065693799d80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParthPatel-ES/PoolNet/blob/master/ResNet_Quant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxsEZIi-8vge",
        "colab_type": "text"
      },
      "source": [
        "#Quntization ResNet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxT3dQQuuaOW",
        "colab_type": "text"
      },
      "source": [
        "### Full ResNet50 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR2ja8kwH0q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.utils import load_state_dict_from_url\n",
        "import torch.optim as optim\n",
        "\n",
        "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
        "           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n",
        "           'wide_resnet50_2', 'wide_resnet101_2']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "    'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
        "    'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
        "    'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
        "    'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
        "}\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
        "\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        if groups != 1 or base_width != 64:\n",
        "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
        "        if dilation > 1:\n",
        "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
        "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = norm_layer(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = norm_layer(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    # Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)\n",
        "    # while original implementation places the stride at the first 1x1 convolution(self.conv1)\n",
        "    # according to \"Deep residual learning for image recognition\"https://arxiv.org/abs/1512.03385.\n",
        "    # This variant is also known as ResNet V1.5 and improves accuracy according to\n",
        "    # https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.\n",
        "\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
        "                 base_width=64, dilation=1, norm_layer=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        width = int(planes * (base_width / 64.)) * groups\n",
        "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
        "        self.conv1 = conv1x1(inplanes, width)\n",
        "        self.bn1 = norm_layer(width)\n",
        "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
        "        self.bn2 = norm_layer(width)\n",
        "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
        "        self.bn3 = norm_layer(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
        "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
        "                 norm_layer=None):\n",
        "        super(ResNet, self).__init__()\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm2d\n",
        "        self._norm_layer = norm_layer\n",
        "\n",
        "        self.inplanes = 64\n",
        "        self.dilation = 1\n",
        "        if replace_stride_with_dilation is None:\n",
        "            # each element in the tuple indicates if we should replace\n",
        "            # the 2x2 stride with a dilated convolution instead\n",
        "            replace_stride_with_dilation = [False, False, False]\n",
        "        if len(replace_stride_with_dilation) != 3:\n",
        "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
        "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
        "        self.groups = groups\n",
        "        self.base_width = width_per_group\n",
        "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = norm_layer(self.inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[0])\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[1])\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
        "                                       dilate=replace_stride_with_dilation[2])\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
        "        norm_layer = self._norm_layer\n",
        "        downsample = None\n",
        "        previous_dilation = self.dilation\n",
        "        if dilate:\n",
        "            self.dilation *= stride\n",
        "            stride = 1\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                norm_layer(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
        "                            self.base_width, previous_dilation, norm_layer))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
        "                                base_width=self.base_width, dilation=self.dilation,\n",
        "                                norm_layer=norm_layer))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # See note [TorchScript super()]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, **kwargs):\n",
        "    model = ResNet(block, layers, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet50(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"ResNet-50 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress,\n",
        "                   **kwargs)\n",
        "\n",
        "\n",
        "only_model = resnet50()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEVppQ1dWMFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1292eb57-6506-4ad7-caca-c2adcc4049c2"
      },
      "source": [
        "print(only_model)\n",
        "torch.save(only_model, 'fullPB.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MvqbTxYcX1FM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dec3c14c-90dc-4386-e03e-94996b35e0f4"
      },
      "source": [
        "print(only_model)\n",
        "torch.save(only_model.state_dict(), 'full.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iBYkM4tulos",
        "colab_type": "text"
      },
      "source": [
        "### ResNet-50 Quant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM_WEKFk0oR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision.models.resnet import Bottleneck, BasicBlock, ResNet, model_urls\n",
        "import torch.nn as nn\n",
        "from torchvision.models.utils import load_state_dict_from_url\n",
        "from torch.quantization import QuantStub, DeQuantStub, fuse_modules\n",
        "from torch._jit_internal import Optional\n",
        "from torchvision.models.quantization.utils import _replace_relu, quantize_model\n",
        "\n",
        "__all__ = ['QuantizableResNet', 'resnet18', 'resnet50',\n",
        "           'resnext101_32x8d']\n",
        "\n",
        "\n",
        "quant_model_urls = {\n",
        "    'resnet18_fbgemm':\n",
        "        'https://download.pytorch.org/models/quantized/resnet18_fbgemm_16fa66dd.pth',\n",
        "    'resnet50_fbgemm':\n",
        "        'https://download.pytorch.org/models/quantized/resnet50_fbgemm_bf931d71.pth',\n",
        "    'resnext101_32x8d_fbgemm':\n",
        "        'https://download.pytorch.org/models/quantized/resnext101_32x8_fbgemm_09835ccf.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class QuantizableBasicBlock(BasicBlock):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(QuantizableBasicBlock, self).__init__(*args, **kwargs)\n",
        "        self.add_relu = torch.nn.quantized.FloatFunctional()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.add_relu.add_relu(out, identity)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def fuse_model(self):\n",
        "        torch.quantization.fuse_modules(self, [['conv1', 'bn1', 'relu'],\n",
        "                                               ['conv2', 'bn2']], inplace=True)\n",
        "        if self.downsample:\n",
        "            torch.quantization.fuse_modules(self.downsample, ['0', '1'], inplace=True)\n",
        "\n",
        "\n",
        "class QuantizableBottleneck(Bottleneck):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(QuantizableBottleneck, self).__init__(*args, **kwargs)\n",
        "        self.skip_add_relu = nn.quantized.FloatFunctional()\n",
        "        self.relu1 = nn.ReLU(inplace=False)\n",
        "        self.relu2 = nn.ReLU(inplace=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out = self.skip_add_relu.add_relu(out, identity)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def fuse_model(self):\n",
        "        fuse_modules(self, [['conv1', 'bn1', 'relu1'],\n",
        "                            ['conv2', 'bn2', 'relu2'],\n",
        "                            ['conv3', 'bn3']], inplace=True)\n",
        "        if self.downsample:\n",
        "            torch.quantization.fuse_modules(self.downsample, ['0', '1'], inplace=True)\n",
        "\n",
        "\n",
        "class QuantizableResNet(ResNet):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(QuantizableResNet, self).__init__(*args, **kwargs)\n",
        "\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        # Ensure scriptability\n",
        "        # super(QuantizableResNet,self).forward(x)\n",
        "        # is not scriptable\n",
        "        x = self._forward_impl(x)\n",
        "        x = self.dequant(x)\n",
        "        return x\n",
        "\n",
        "    def fuse_model(self):\n",
        "        r\"\"\"Fuse conv/bn/relu modules in resnet models\n",
        "        Fuse conv+bn+relu/ Conv+relu/conv+Bn modules to prepare for quantization.\n",
        "        Model is modified in place.  Note that this operation does not change numerics\n",
        "        and the model after modification is in floating point\n",
        "        \"\"\"\n",
        "\n",
        "        fuse_modules(self, ['conv1', 'bn1', 'relu'], inplace=True)\n",
        "        for m in self.modules():\n",
        "            if type(m) == QuantizableBottleneck or type(m) == QuantizableBasicBlock:\n",
        "                m.fuse_model()\n",
        "\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, quantize, **kwargs):\n",
        "    model = QuantizableResNet(block, layers, **kwargs)\n",
        "    _replace_relu(model)\n",
        "    if quantize:\n",
        "        # TODO use pretrained as a string to specify the backend\n",
        "        backend = 'fbgemm'\n",
        "        quantize_model(model, backend)\n",
        "    else:\n",
        "        assert pretrained in [True, False]\n",
        "\n",
        "    if pretrained:\n",
        "        if quantize:\n",
        "            model_url = quant_model_urls[arch + '_' + backend]\n",
        "        else:\n",
        "            model_url = model_urls[arch]\n",
        "\n",
        "        state_dict = load_state_dict_from_url(model_url,\n",
        "                                              progress=progress)\n",
        "\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "def resnet50(pretrained=True , progress=True, quantize=True, **kwargs):\n",
        "    r\"\"\"ResNet-50 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet50', QuantizableBottleneck, [3, 4, 6, 3], pretrained, progress,\n",
        "                   quantize, **kwargs)\n",
        "def resnet18(pretrained=False, progress=True, quantize=True, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', QuantizableBasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
        "                   quantize, **kwargs)\n",
        "    \n",
        "modelQ = resnet18()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4MVxOOHWcOiA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f156ce5b-1922-4850-d1a9-ae2047e646f9"
      },
      "source": [
        "print(modelQ)\n",
        "#torch.save(modelQ, 'test.pth')   not supported\n",
        "torch.save(modelQ.state_dict(), 'test.pth')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QuantizableResNet(\n",
            "  (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.0055027129128575325, zero_point=0, padding=(3, 3))\n",
            "  (bn1): Identity()\n",
            "  (relu): Identity()\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): QuantizableBasicBlock(\n",
            "      (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.006579339969903231, zero_point=0, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): Identity()\n",
            "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.014941861853003502, zero_point=54, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (add_relu): QFunctional(\n",
            "        scale=0.010246247984468937, zero_point=0\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): QuantizableBasicBlock(\n",
            "      (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.011978307738900185, zero_point=0, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): Identity()\n",
            "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.026276491582393646, zero_point=64, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (add_relu): QFunctional(\n",
            "        scale=0.015430987812578678, zero_point=0\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): QuantizableBasicBlock(\n",
            "      (conv1): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.012188863009214401, zero_point=0, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): Identity()\n",
            "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.021572649478912354, zero_point=64, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (downsample): Sequential(\n",
            "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.029818253591656685, zero_point=58)\n",
            "        (1): Identity()\n",
            "      )\n",
            "      (add_relu): QFunctional(\n",
            "        scale=0.018866760656237602, zero_point=0\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): QuantizableBasicBlock(\n",
            "      (conv1): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.014750456437468529, zero_point=0, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): Identity()\n",
            "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.03368528559803963, zero_point=64, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (add_relu): QFunctional(\n",
            "        scale=0.02325865626335144, zero_point=0\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): QuantizableBasicBlock(\n",
            "      (conv1): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.01977545954287052, zero_point=0, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): Identity()\n",
            "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.038887377828359604, zero_point=62, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (downsample): Sequential(\n",
            "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.03884442523121834, zero_point=62)\n",
            "        (1): Identity()\n",
            "      )\n",
            "      (add_relu): QFunctional(\n",
            "        scale=0.032691046595573425, zero_point=0\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): QuantizableBasicBlock(\n",
            "      (conv1): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.02860930748283863, zero_point=0, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): Identity()\n",
            "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.05968663841485977, zero_point=55, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (add_relu): QFunctional(\n",
            "        scale=0.0417078360915184, zero_point=0\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): QuantizableBasicBlock(\n",
            "      (conv1): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.03152498975396156, zero_point=0, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): Identity()\n",
            "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.07546383887529373, zero_point=68, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (downsample): Sequential(\n",
            "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.0725395604968071, zero_point=62)\n",
            "        (1): Identity()\n",
            "      )\n",
            "      (add_relu): QFunctional(\n",
            "        scale=0.045539502054452896, zero_point=0\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "    (1): QuantizableBasicBlock(\n",
            "      (conv1): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.042931802570819855, zero_point=0, padding=(1, 1))\n",
            "      (bn1): Identity()\n",
            "      (relu): Identity()\n",
            "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.09456417709589005, zero_point=68, padding=(1, 1))\n",
            "      (bn2): Identity()\n",
            "      (add_relu): QFunctional(\n",
            "        scale=0.06539027392864227, zero_point=0\n",
            "        (activation_post_process): Identity()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): QuantizedLinear(in_features=512, out_features=1000, scale=0.043148886412382126, zero_point=63, qscheme=torch.per_channel_affine)\n",
            "  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
            "  (dequant): DeQuantize()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpMb7sA5XvyB",
        "colab_type": "text"
      },
      "source": [
        "### Try Quant"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-KGyInjXnT1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import zipfile\n",
        "\n",
        "url = 'https://s3.amazonaws.com/pytorch-tutorial-assets/imagenet_1k.zip'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "\n",
        "open('imagenet_1k.zip', 'wb').write(r.content)\n",
        "\n",
        "with zipfile.ZipFile('/content/imagenet_1k.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ2_i6a9wCZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a8fc0bf-2521-444a-94d4-a4db65787f30"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "import torch.quantization\n",
        "\n",
        "# # Setup warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\n",
        "    action='ignore',\n",
        "    category=DeprecationWarning,\n",
        "    module=r'.*'\n",
        ")\n",
        "warnings.filterwarnings(\n",
        "    action='default',\n",
        "    module=r'torch.quantization'\n",
        ")\n",
        "\n",
        "# Specify random seed for repeatable results\n",
        "torch.manual_seed(191009)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fec0bf28f78>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su0KeX0HwSOH",
        "colab_type": "text"
      },
      "source": [
        "### mobilenet working test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0hYY2CTwTSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.quantization import QuantStub, DeQuantStub\n",
        "\n",
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    :param v:\n",
        "    :param divisor:\n",
        "    :param min_value:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "class ConvBNReLU(nn.Sequential):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, groups=1):\n",
        "        padding = (kernel_size - 1) // 2\n",
        "        super(ConvBNReLU, self).__init__(\n",
        "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False),\n",
        "            nn.BatchNorm2d(out_planes, momentum=0.1),\n",
        "            # Replace with ReLU\n",
        "            nn.ReLU(inplace=False)\n",
        "        )\n",
        "\n",
        "\n",
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(self, inp, oup, stride, expand_ratio):\n",
        "        super(InvertedResidual, self).__init__()\n",
        "        self.stride = stride\n",
        "        assert stride in [1, 2]\n",
        "\n",
        "        hidden_dim = int(round(inp * expand_ratio))\n",
        "        self.use_res_connect = self.stride == 1 and inp == oup\n",
        "\n",
        "        layers = []\n",
        "        if expand_ratio != 1:\n",
        "            # pw\n",
        "            layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=1))\n",
        "        layers.extend([\n",
        "            # dw\n",
        "            ConvBNReLU(hidden_dim, hidden_dim, stride=stride, groups=hidden_dim),\n",
        "            # pw-linear\n",
        "            nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(oup, momentum=0.1),\n",
        "        ])\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "        # Replace torch.add with floatfunctional\n",
        "        self.skip_add = nn.quantized.FloatFunctional()\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_res_connect:\n",
        "            return self.skip_add.add(x, self.conv(x))\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "    def __init__(self, num_classes=1000, width_mult=1.0, inverted_residual_setting=None, round_nearest=8):\n",
        "        \"\"\"\n",
        "        MobileNet V2 main class\n",
        "\n",
        "        Args:\n",
        "            num_classes (int): Number of classes\n",
        "            width_mult (float): Width multiplier - adjusts number of channels in each layer by this amount\n",
        "            inverted_residual_setting: Network structure\n",
        "            round_nearest (int): Round the number of channels in each layer to be a multiple of this number\n",
        "            Set to 1 to turn off rounding\n",
        "        \"\"\"\n",
        "        super(MobileNetV2, self).__init__()\n",
        "        block = InvertedResidual\n",
        "        input_channel = 32\n",
        "        last_channel = 1280\n",
        "\n",
        "        if inverted_residual_setting is None:\n",
        "            inverted_residual_setting = [\n",
        "                # t, c, n, s\n",
        "                [1, 16, 1, 1],\n",
        "                [6, 24, 2, 2],\n",
        "                [6, 32, 3, 2],\n",
        "                [6, 64, 4, 2],\n",
        "                [6, 96, 3, 1],\n",
        "                [6, 160, 3, 2],\n",
        "                [6, 320, 1, 1],\n",
        "            ]\n",
        "\n",
        "        # only check the first element, assuming user knows t,c,n,s are required\n",
        "        if len(inverted_residual_setting) == 0 or len(inverted_residual_setting[0]) != 4:\n",
        "            raise ValueError(\"inverted_residual_setting should be non-empty \"\n",
        "                             \"or a 4-element list, got {}\".format(inverted_residual_setting))\n",
        "\n",
        "        # building first layer\n",
        "        input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
        "        self.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\n",
        "        features = [ConvBNReLU(3, input_channel, stride=2)]\n",
        "        # building inverted residual blocks\n",
        "        for t, c, n, s in inverted_residual_setting:\n",
        "            output_channel = _make_divisible(c * width_mult, round_nearest)\n",
        "            for i in range(n):\n",
        "                stride = s if i == 0 else 1\n",
        "                features.append(block(input_channel, output_channel, stride, expand_ratio=t))\n",
        "                input_channel = output_channel\n",
        "        # building last several layers\n",
        "        features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1))\n",
        "        # make it nn.Sequential\n",
        "        self.features = nn.Sequential(*features)\n",
        "        self.quant = QuantStub()\n",
        "        self.dequant = DeQuantStub()\n",
        "        # building classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(self.last_channel, num_classes),\n",
        "        )\n",
        "\n",
        "        # weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.quant(x)\n",
        "\n",
        "        x = self.features(x)\n",
        "        x = x.mean([2, 3])\n",
        "        x = self.classifier(x)\n",
        "        x = self.dequant(x)\n",
        "        return x\n",
        "\n",
        "    # Fuse Conv+BN and Conv+BN+Relu modules prior to quantization\n",
        "    # This operation does not change the numerics\n",
        "    def fuse_model(self):\n",
        "        for m in self.modules():\n",
        "            if type(m) == ConvBNReLU:\n",
        "                torch.quantization.fuse_modules(m, ['0', '1', '2'], inplace=True)\n",
        "            if type(m) == InvertedResidual:\n",
        "                for idx in range(len(m.conv)):\n",
        "                    if type(m.conv[idx]) == nn.Conv2d:\n",
        "                        torch.quantization.fuse_modules(m.conv, [str(idx), str(idx + 1)], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cS6RPb51whj1",
        "colab_type": "text"
      },
      "source": [
        "### Rest same for other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr381jrLwsje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "\n",
        "def evaluate(model, criterion, data_loader, neval_batches):\n",
        "    model.eval()\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        for image, target in data_loader:\n",
        "            output = model(image)\n",
        "            loss = criterion(output, target)\n",
        "            cnt += 1\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "            print('.', end = '')\n",
        "            top1.update(acc1[0], image.size(0))\n",
        "            top5.update(acc5[0], image.size(0))\n",
        "            if cnt >= neval_batches:\n",
        "                 return top1, top5\n",
        "\n",
        "    return top1, top5\n",
        "\n",
        "def load_model(model_file):\n",
        "    model = MobileNetV2()#resnet50() #\n",
        "    state_dict = torch.load(model_file)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.to('cpu')\n",
        "    return model\n",
        "\n",
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "    os.remove('temp.p')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVXEyE9by9xK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data_loaders(data_path):\n",
        "\n",
        "    traindir = os.path.join(data_path, 'train')\n",
        "    valdir = os.path.join(data_path, 'val')\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    dataset = torchvision.datasets.ImageFolder(\n",
        "        traindir,\n",
        "        transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]))\n",
        "\n",
        "    dataset_test = torchvision.datasets.ImageFolder(\n",
        "        valdir,\n",
        "        transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]))\n",
        "\n",
        "    train_sampler = torch.utils.data.RandomSampler(dataset)\n",
        "    test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=train_batch_size,\n",
        "        sampler=train_sampler)\n",
        "\n",
        "    data_loader_test = torch.utils.data.DataLoader(\n",
        "        dataset_test, batch_size=eval_batch_size,\n",
        "        sampler=test_sampler)\n",
        "\n",
        "    return data_loader, data_loader_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OmoorWi0zVJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "663d38d7-d9f4-47d4-d839-4c10dafbe8c7"
      },
      "source": [
        "import requests\n",
        "\n",
        "url = 'https://download.pytorch.org/models/mobilenet_v2-b0353104.pth'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('./data/mobilenet_pretrained_float.pth', 'wb').write(r.content)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14212972"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUiBo4s1zCIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/data/imagenet_1k'\n",
        "saved_model_dir = 'data/'\n",
        "float_model_file = 'mobilenet_pretrained_float.pth' #'test.pth' #\n",
        "scripted_float_model_file = 'resnet_quantization_scripted.pth'\n",
        "scripted_quantized_model_file = 'resnet_quantization_scripted_quantized.pth'\n",
        "\n",
        "train_batch_size = 30\n",
        "eval_batch_size = 30\n",
        "\n",
        "data_loader, data_loader_test = prepare_data_loaders(data_path)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "float_model = load_model(saved_model_dir + float_model_file).to('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yyty-LjqzJM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "c29af7d8-cea5-438c-d130-8ee65faa1826"
      },
      "source": [
        "print('\\n Inverted Residual Block: Before fusion \\n\\n', float_model.features[1].conv)\n",
        "float_model.eval()\n",
        "\n",
        "# Fuses modules\n",
        "float_model.fuse_model()\n",
        "\n",
        "# Note fusion of Conv+BN+Relu and Conv+Relu\n",
        "print('\\n Inverted Residual Block: After fusion\\n\\n',float_model.features[1].conv)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Inverted Residual Block: Before fusion \n",
            "\n",
            " Sequential(\n",
            "  (0): ConvBNReLU(\n",
            "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "  )\n",
            "  (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n",
            "\n",
            " Inverted Residual Block: After fusion\n",
            "\n",
            " Sequential(\n",
            "  (0): ConvBNReLU(\n",
            "    (0): ConvReLU2d(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32)\n",
            "      (1): ReLU()\n",
            "    )\n",
            "    (1): Identity()\n",
            "    (2): Identity()\n",
            "  )\n",
            "  (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (2): Identity()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccKV1bqezPjb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0eb87ebd-1423-4243-f145-d9e5d1321da8"
      },
      "source": [
        "num_eval_batches = 10\n",
        "\n",
        "print(\"Size of baseline model\")\n",
        "print_size_of_model(float_model)\n",
        "\n",
        "top1, top5 = evaluate(float_model, criterion, data_loader_test, neval_batches=num_eval_batches)\n",
        "print('Evaluation accuracy on %d images, %2.2f'%(num_eval_batches * eval_batch_size, top1.avg))\n",
        "torch.jit.save(torch.jit.script(float_model), saved_model_dir + scripted_float_model_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of baseline model\n",
            "Size (MB): 13.998506\n",
            "..........Evaluation accuracy on 300 images, 78.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M6QA1Bu2rvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_calibration_batches = 10\n",
        "\n",
        "myModel = load_model(saved_model_dir + float_model_file).to('cpu')\n",
        "myModel.eval()\n",
        "\n",
        "# Fuse Conv, bn and relu\n",
        "myModel.fuse_model()\n",
        "\n",
        "# Specify quantization configuration\n",
        "# Start with simple min/max range estimation and per-tensor quantization of weights\n",
        "myModel.qconfig = torch.quantization.default_qconfig\n",
        "print(myModel.qconfig)\n",
        "torch.quantization.prepare(myModel, inplace=True)\n",
        "\n",
        "# Calibrate first\n",
        "print('Post Training Quantization Prepare: Inserting Observers')\n",
        "print('\\n Inverted Residual Block:After observer insertion \\n\\n', myModel.features[1].conv)\n",
        "\n",
        "# Calibrate with the training set\n",
        "evaluate(myModel, criterion, data_loader, neval_batches=num_calibration_batches)\n",
        "print('Post Training Quantization: Calibration done')\n",
        "\n",
        "# Convert to quantized model\n",
        "torch.quantization.convert(myModel, inplace=True)\n",
        "print('Post Training Quantization: Convert done')\n",
        "print('\\n Inverted Residual Block: After fusion and quantization, note fused modules: \\n\\n',myModel.features[1].conv)\n",
        "\n",
        "print(\"Size of model after quantization\")\n",
        "print_size_of_model(myModel)\n",
        "\n",
        "top1, top5 = evaluate(myModel, criterion, data_loader_test, neval_batches=num_eval_batches)\n",
        "print('Evaluation accuracy on %d images, %2.2f'%(num_eval_batches * eval_batch_size, top1.avg))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1G7LlGJzbZu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "f20a7c1f-1181-43ef-ca1e-aecc5f5b3909"
      },
      "source": [
        "per_channel_quantized_model = load_model(saved_model_dir + float_model_file)\n",
        "per_channel_quantized_model.eval()\n",
        "per_channel_quantized_model.fuse_model()\n",
        "per_channel_quantized_model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "print(per_channel_quantized_model.qconfig)\n",
        "\n",
        "torch.quantization.prepare(per_channel_quantized_model, inplace=True)\n",
        "evaluate(per_channel_quantized_model,criterion, data_loader, num_calibration_batches)\n",
        "torch.quantization.convert(per_channel_quantized_model, inplace=True)\n",
        "top1, top5 = evaluate(per_channel_quantized_model, criterion, data_loader_test, neval_batches=num_eval_batches)\n",
        "print('Evaluation accuracy on %d images, %2.2f'%(num_eval_batches * eval_batch_size, top1.avg))\n",
        "torch.jit.save(torch.jit.script(per_channel_quantized_model), saved_model_dir + scripted_quantized_model_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QConfig(activation=functools.partial(<class 'torch.quantization.observer.HistogramObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.PerChannelMinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_channel_symmetric))\n",
            ".........."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/quantization/observer.py:877: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
            "  Returning default scale and zero point \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "..........Evaluation accuracy on 300 images, 74.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKuOLvQyur63",
        "colab_type": "text"
      },
      "source": [
        "### Test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mSAu0k7WKUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o6W-Ks1WUi8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXzSvxELV7yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print model's state_dict\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eGgesCUWWxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Print optimizer's state_dict\n",
        "print(\"Optimizer's state_dict:\")\n",
        "for var_name in optimizer.state_dict():\n",
        "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XROZJgHJbWG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/drive/My Drive/Colab Notebooks/Q models/full.pth' /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwZPHJwubeRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "model = torch.load('test.pth')\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MepiBxTYcBYB",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "model = torch.load('full.pth')\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "u_JjhObac6dk",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "model = torch.load('fullPB.pth')\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "89218HjTcy9X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88a558a7-dc88-40e9-8b02-b73adaf2d51b"
      },
      "source": [
        "import torch\n",
        "model = model.load_state_dict(torch.load('full.pth'))\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<All keys matched successfully>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHZ4UYAr7Igo",
        "colab_type": "text"
      },
      "source": [
        "# PoolNet Quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofZ6ZfjM7t-1",
        "colab_type": "text"
      },
      "source": [
        "### ResNet50 modified model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omlBoulW7HeM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "affine_par = True\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes, affine = affine_par)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes, affine = affine_par)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1,  dilation_ = 1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False) # change\n",
        "        self.bn1 = nn.BatchNorm2d(planes,affine = affine_par)\n",
        "        for i in self.bn1.parameters():\n",
        "            i.requires_grad = False\n",
        "        padding = 1\n",
        "        if dilation_ == 2:\n",
        "            padding = 2\n",
        "        elif dilation_ == 4:\n",
        "            padding = 4\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, # change\n",
        "                               padding=padding, bias=False, dilation = dilation_)\n",
        "        self.bn2 = nn.BatchNorm2d(planes,affine = affine_par)\n",
        "        for i in self.bn2.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4, affine = affine_par)\n",
        "        for i in self.bn3.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64,affine = affine_par)\n",
        "        for i in self.bn1.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True) # change\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation__ = 2)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1,dilation__ = 1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion or dilation__ == 2 or dilation__ == 4:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion,affine = affine_par),\n",
        "            )\n",
        "        for i in downsample._modules['1'].parameters():\n",
        "            i.requires_grad = False\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride,dilation_=dilation__, downsample = downsample ))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes,dilation_=dilation__))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        tmp_x = []\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        tmp_x.append(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        tmp_x.append(x)\n",
        "        x = self.layer2(x)\n",
        "        tmp_x.append(x)\n",
        "        x = self.layer3(x)\n",
        "        tmp_x.append(x)\n",
        "        x = self.layer4(x)\n",
        "        tmp_x.append(x)\n",
        "\n",
        "        return tmp_x\n",
        "\n",
        "\n",
        "class ResNet_locate(nn.Module):\n",
        "    def __init__(self, block, layers):\n",
        "        super(ResNet_locate,self).__init__()\n",
        "        self.resnet = ResNet(block, layers)\n",
        "        self.in_planes = 512\n",
        "        self.out_planes = [512, 256, 256, 128]\n",
        "\n",
        "        self.ppms_pre = nn.Conv2d(2048, self.in_planes, 1, 1, bias=False)\n",
        "        ppms, infos = [], []\n",
        "        for ii in [1, 3, 5]:\n",
        "            ppms.append(nn.Sequential(nn.AdaptiveAvgPool2d(ii), nn.Conv2d(self.in_planes, self.in_planes, 1, 1, bias=False), nn.ReLU(inplace=True)))\n",
        "        self.ppms = nn.ModuleList(ppms)\n",
        "\n",
        "        self.ppm_cat = nn.Sequential(nn.Conv2d(self.in_planes * 4, self.in_planes, 3, 1, 1, bias=False), nn.ReLU(inplace=True))\n",
        "        for ii in self.out_planes:\n",
        "            infos.append(nn.Sequential(nn.Conv2d(self.in_planes, ii, 3, 1, 1, bias=False), nn.ReLU(inplace=True)))\n",
        "        self.infos = nn.ModuleList(infos)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def load_pretrained_model(self, model):\n",
        "        self.resnet.load_state_dict(model, strict=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_size = x.size()[2:]\n",
        "        xs = self.resnet(x)\n",
        "\n",
        "        xs_1 = self.ppms_pre(xs[-1])\n",
        "        xls = [xs_1]\n",
        "        for k in range(len(self.ppms)):\n",
        "            xls.append(F.interpolate(self.ppms[k](xs_1), xs_1.size()[2:], mode='bilinear', align_corners=True))\n",
        "        xls = self.ppm_cat(torch.cat(xls, dim=1))\n",
        "\n",
        "        infos = []\n",
        "        for k in range(len(self.infos)):\n",
        "            infos.append(self.infos[k](F.interpolate(xls, xs[len(self.infos) - 1 - k].size()[2:], mode='bilinear', align_corners=True)))\n",
        "\n",
        "        return xs, infos\n",
        "\n",
        "def resnet50_locate():\n",
        "    model = ResNet_locate(Bottleneck, [3, 4, 6, 3])\n",
        "    return model\n",
        "\n",
        "PN_model = resnet50_locate()\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8Fc_5mWcWbX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "826df174-df23-4b9f-d458-11499b1de08d"
      },
      "source": [
        "PN_model.eval()\n",
        "\n",
        "import torch.nn as nn\n",
        "from torchvision.models.utils import load_state_dict_from_url\n",
        "from torch.quantization import QuantStub, DeQuantStub, fuse_modules\n",
        "from torch._jit_internal import Optional\n",
        "from torchvision.models.quantization.utils import _replace_relu, quantize_model\n",
        "\n",
        "__all__ = ['QuantizableResNet', 'resnet18', 'resnet50',\n",
        "           'resnext101_32x8d']\n",
        "\n",
        "\n",
        "quant_model_urls = {\n",
        "    'resnet18_fbgemm':\n",
        "        'https://download.pytorch.org/models/quantized/resnet18_fbgemm_16fa66dd.pth',\n",
        "    'resnet50_fbgemm':\n",
        "        'https://download.pytorch.org/models/quantized/resnet50_fbgemm_bf931d71.pth',\n",
        "    'resnext101_32x8d_fbgemm':\n",
        "        'https://download.pytorch.org/models/quantized/resnext101_32x8_fbgemm_09835ccf.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class QuantizableBasicBlock(BasicBlock):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(QuantizableBasicBlock, self).__init__(*args, **kwargs)\n",
        "        self.add_relu = torch.nn.quantized.FloatFunctional()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.add_relu.add_relu(out, identity)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def fuse_model(self):\n",
        "        torch.quantization.fuse_modules(self, [['conv1', 'bn1', 'relu'],\n",
        "                                               ['conv2', 'bn2']], inplace=True)\n",
        "        if self.downsample:\n",
        "            torch.quantization.fuse_modules(self.downsample, ['0', '1'], inplace=True)\n",
        "\n",
        "\n",
        "class QuantizableBottleneck(Bottleneck):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(QuantizableBottleneck, self).__init__(*args, **kwargs)\n",
        "        self.skip_add_relu = nn.quantized.FloatFunctional()\n",
        "        self.relu1 = nn.ReLU(inplace=False)\n",
        "        self.relu2 = nn.ReLU(inplace=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out = self.skip_add_relu.add_relu(out, identity)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def fuse_model(self):\n",
        "        fuse_modules(self, [['conv1', 'bn1', 'relu1'],\n",
        "                            ['conv2', 'bn2', 'relu2'],\n",
        "                            ['conv3', 'bn3']], inplace=True)\n",
        "        if self.downsample:\n",
        "            torch.quantization.fuse_modules(self.downsample, ['0', '1'], inplace=True)\n",
        "\n",
        "\n",
        "class QuantizableResNet(ResNet):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(QuantizableResNet, self).__init__(*args, **kwargs)\n",
        "\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        # Ensure scriptability\n",
        "        #super(QuantizableResNet,self).forward(x)\n",
        "        # is not scriptable\n",
        "        #x = self._forward_impl(x)\n",
        "        x = self.dequant(x)\n",
        "        return x\n",
        "\n",
        "    def fuse_model(self):\n",
        "        r\"\"\"Fuse conv/bn/relu modules in resnet models\n",
        "        Fuse conv+bn+relu/ Conv+relu/conv+Bn modules to prepare for quantization.\n",
        "        Model is modified in place.  Note that this operation does not change numerics\n",
        "        and the model after modification is in floating point\n",
        "        \"\"\"\n",
        "\n",
        "        fuse_modules(self, ['conv1', 'bn1', 'relu'], inplace=True)\n",
        "        for m in self.modules():\n",
        "            if type(m) == QuantizableBottleneck or type(m) == QuantizableBasicBlock:\n",
        "                m.fuse_model()\n",
        "\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, quantize, **kwargs):\n",
        "    model = QuantizableResNet(block, layers, **kwargs)\n",
        "    _replace_relu(model)\n",
        "    if quantize:\n",
        "        # TODO use pretrained as a string to specify the backend\n",
        "        backend = 'fbgemm'\n",
        "        quantize_model(model, backend)\n",
        "    else:\n",
        "        assert pretrained in [True, False]\n",
        "\n",
        "    if pretrained:\n",
        "        if quantize:\n",
        "            model_url = quant_model_urls[arch + '_' + backend]\n",
        "        else:\n",
        "            model_url = model_urls[arch]\n",
        "\n",
        "        state_dict = load_state_dict_from_url(model_url,\n",
        "                                              progress=progress)\n",
        "\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "def resnet50(pretrained=False , progress=True, quantize=True, **kwargs):\n",
        "    r\"\"\"ResNet-50 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet50', QuantizableBottleneck, [3, 4, 6, 3], pretrained, progress,\n",
        "                   quantize, **kwargs)\n",
        "def resnet18(pretrained=False, progress=True, quantize=False, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', QuantizableBasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
        "                   quantize, **kwargs)\n",
        "    \n",
        "modelQ = resnet50(quantize=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/quantization/observer.py:136: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
            "  Returning default scale and zero point \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heLaxXRxjXi2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7298b62-99f3-482a-adef-e6cd94d5ec33"
      },
      "source": [
        "modelQ.eval()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizableResNet(\n",
              "  (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=1.0, zero_point=0, padding=(3, 3))\n",
              "  (bn1): Identity()\n",
              "  (relu): Identity()\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): QuantizableBottleneck(\n",
              "      (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn1): Identity()\n",
              "      (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn3): Identity()\n",
              "      (relu): QuantizedReLU()\n",
              "      (downsample): Sequential(\n",
              "        (0): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (skip_add_relu): QFunctional(\n",
              "        scale=1.0, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (relu1): Identity()\n",
              "      (relu2): Identity()\n",
              "    )\n",
              "    (1): QuantizableBottleneck(\n",
              "      (conv1): QuantizedConvReLU2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn1): Identity()\n",
              "      (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn3): Identity()\n",
              "      (relu): QuantizedReLU()\n",
              "      (skip_add_relu): QFunctional(\n",
              "        scale=1.0, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (relu1): Identity()\n",
              "      (relu2): Identity()\n",
              "    )\n",
              "    (2): QuantizableBottleneck(\n",
              "      (conv1): QuantizedConvReLU2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn1): Identity()\n",
              "      (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn3): Identity()\n",
              "      (relu): QuantizedReLU()\n",
              "      (skip_add_relu): QFunctional(\n",
              "        scale=1.0, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (relu1): Identity()\n",
              "      (relu2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): QuantizableBottleneck(\n",
              "      (conv1): QuantizedConvReLU2d(256, 128, kernel_size=(1, 1), stride=(2, 2), scale=1.0, zero_point=0)\n",
              "      (bn1): Identity()\n",
              "      (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn3): Identity()\n",
              "      (relu): QuantizedReLU()\n",
              "      (downsample): Sequential(\n",
              "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=1.0, zero_point=0)\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (skip_add_relu): QFunctional(\n",
              "        scale=1.0, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (relu1): Identity()\n",
              "      (relu2): Identity()\n",
              "    )\n",
              "    (1): QuantizableBottleneck(\n",
              "      (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn1): Identity()\n",
              "      (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn3): Identity()\n",
              "      (relu): QuantizedReLU()\n",
              "      (skip_add_relu): QFunctional(\n",
              "        scale=1.0, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (relu1): Identity()\n",
              "      (relu2): Identity()\n",
              "    )\n",
              "    (2): QuantizableBottleneck(\n",
              "      (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn1): Identity()\n",
              "      (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn3): Identity()\n",
              "      (relu): QuantizedReLU()\n",
              "      (skip_add_relu): QFunctional(\n",
              "        scale=1.0, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (relu1): Identity()\n",
              "      (relu2): Identity()\n",
              "    )\n",
              "    (3): QuantizableBottleneck(\n",
              "      (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn1): Identity()\n",
              "      (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn3): Identity()\n",
              "      (relu): QuantizedReLU()\n",
              "      (skip_add_relu): QFunctional(\n",
              "        scale=1.0, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (relu1): Identity()\n",
              "      (relu2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): QuantizableBottleneck(\n",
              "      (conv1): QuantizedConvReLU2d(512, 256, kernel_size=(1, 1), stride=(2, 2), scale=1.0, zero_point=0)\n",
              "      (bn1): Identity()\n",
              "      (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn3): Identity()\n",
              "      (relu): QuantizedReLU()\n",
              "      (downsample): Sequential(\n",
              "        (0): QuantizedConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), scale=1.0, zero_point=0)\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (skip_add_relu): QFunctional(\n",
              "        scale=1.0, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (relu1): Identity()\n",
              "      (relu2): Identity()\n",
              "    )\n",
              "    (1): QuantizableBottleneck(\n",
              "      (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn1): Identity()\n",
              "      (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn3): Identity()\n",
              "      (relu): QuantizedReLU()\n",
              "      (skip_add_relu): QFunctional(\n",
              "        scale=1.0, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (relu1): Identity()\n",
              "      (relu2): Identity()\n",
              "    )\n",
              "    (2): QuantizableBottleneck(\n",
              "      (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn1): Identity()\n",
              "      (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn3): Identity()\n",
              "      (relu): QuantizedReLU()\n",
              "      (skip_add_relu): QFunctional(\n",
              "        scale=1.0, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (relu1): Identity()\n",
              "      (relu2): Identity()\n",
              "    )\n",
              "    (3): QuantizableBottleneck(\n",
              "      (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn1): Identity()\n",
              "      (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn3): Identity()\n",
              "      (relu): QuantizedReLU()\n",
              "      (skip_add_relu): QFunctional(\n",
              "        scale=1.0, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (relu1): Identity()\n",
              "      (relu2): Identity()\n",
              "    )\n",
              "    (4): QuantizableBottleneck(\n",
              "      (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn1): Identity()\n",
              "      (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn3): Identity()\n",
              "      (relu): QuantizedReLU()\n",
              "      (skip_add_relu): QFunctional(\n",
              "        scale=1.0, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (relu1): Identity()\n",
              "      (relu2): Identity()\n",
              "    )\n",
              "    (5): QuantizableBottleneck(\n",
              "      (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn1): Identity()\n",
              "      (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn3): Identity()\n",
              "      (relu): QuantizedReLU()\n",
              "      (skip_add_relu): QFunctional(\n",
              "        scale=1.0, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (relu1): Identity()\n",
              "      (relu2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): QuantizableBottleneck(\n",
              "      (conv1): QuantizedConvReLU2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn1): Identity()\n",
              "      (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(2, 2), dilation=(2, 2))\n",
              "      (bn2): Identity()\n",
              "      (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn3): Identity()\n",
              "      (relu): QuantizedReLU()\n",
              "      (downsample): Sequential(\n",
              "        (0): QuantizedConv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (skip_add_relu): QFunctional(\n",
              "        scale=1.0, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (relu1): Identity()\n",
              "      (relu2): Identity()\n",
              "    )\n",
              "    (1): QuantizableBottleneck(\n",
              "      (conv1): QuantizedConvReLU2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn1): Identity()\n",
              "      (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(2, 2), dilation=(2, 2))\n",
              "      (bn2): Identity()\n",
              "      (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn3): Identity()\n",
              "      (relu): QuantizedReLU()\n",
              "      (skip_add_relu): QFunctional(\n",
              "        scale=1.0, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (relu1): Identity()\n",
              "      (relu2): Identity()\n",
              "    )\n",
              "    (2): QuantizableBottleneck(\n",
              "      (conv1): QuantizedConvReLU2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn1): Identity()\n",
              "      (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(2, 2), dilation=(2, 2))\n",
              "      (bn2): Identity()\n",
              "      (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "      (bn3): Identity()\n",
              "      (relu): QuantizedReLU()\n",
              "      (skip_add_relu): QFunctional(\n",
              "        scale=1.0, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "      (relu1): Identity()\n",
              "      (relu2): Identity()\n",
              "    )\n",
              "  )\n",
              "  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "  (dequant): DeQuantize()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud0_jbLk70ih",
        "colab_type": "text"
      },
      "source": [
        "### ResNet50 PoolNet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmXE4bM71jgU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d3b0f4ae-64ba-44ee-bf50-44407cc8b281"
      },
      "source": [
        "\n",
        "class ResNet_locate(nn.Module):\n",
        "    def __init__(self, block, layers):\n",
        "        super(ResNet_locate,self).__init__()\n",
        "        self.resnet = resnet50(quantize=True) #QuantizableResNet(block, layers)\n",
        "        self.in_planes = 512\n",
        "        self.out_planes = [512, 256, 256, 128]\n",
        "\n",
        "        self.ppms_pre = nn.Conv2d(2048, self.in_planes, 1, 1, bias=False)\n",
        "        ppms, infos = [], []\n",
        "        for ii in [1, 3, 5]:\n",
        "            ppms.append(nn.Sequential(nn.AdaptiveAvgPool2d(ii), nn.Conv2d(self.in_planes, self.in_planes, 1, 1, bias=False), nn.ReLU(inplace=True)))\n",
        "        self.ppms = nn.ModuleList(ppms)\n",
        "\n",
        "        self.ppm_cat = nn.Sequential(nn.Conv2d(self.in_planes * 4, self.in_planes, 3, 1, 1, bias=False), nn.ReLU(inplace=True))\n",
        "        for ii in self.out_planes:\n",
        "            infos.append(nn.Sequential(nn.Conv2d(self.in_planes, ii, 3, 1, 1, bias=False), nn.ReLU(inplace=True)))\n",
        "        self.infos = nn.ModuleList(infos)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def load_pretrained_model(self, model):\n",
        "        self.resnet.load_state_dict(model, strict=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_size = x.size()[2:]\n",
        "        xs = self.resnet(x)\n",
        "\n",
        "        xs_1 = self.ppms_pre(xs[-1])\n",
        "        xls = [xs_1]\n",
        "        for k in range(len(self.ppms)):\n",
        "            xls.append(F.interpolate(self.ppms[k](xs_1), xs_1.size()[2:], mode='bilinear', align_corners=True))\n",
        "        xls = self.ppm_cat(torch.cat(xls, dim=1))\n",
        "\n",
        "        infos = []\n",
        "        for k in range(len(self.infos)):\n",
        "            infos.append(self.infos[k](F.interpolate(xls, xs[len(self.infos) - 1 - k].size()[2:], mode='bilinear', align_corners=True)))\n",
        "\n",
        "        return xs, infos\n",
        "\n",
        "def resnet50_locate():\n",
        "    model = ResNet_locate(QuantizableBottleneck, [3, 4, 6, 3])\n",
        "    return model\n",
        "\n",
        "PN_model = resnet50_locate()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/quantization/observer.py:136: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
            "  Returning default scale and zero point \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el5MpbTe6IOC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "50f34521-18a6-4107-bd7b-d5e0335a712a"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "config_vgg = {'convert': [[128,256,512,512,512],[64,128,256,512,512]], 'deep_pool': [[512, 512, 256, 128], [512, 256, 128, 128], [True, True, True, False], [True, True, True, False]], 'score': 128}  # no convert layer, no conv6\n",
        "\n",
        "config_resnet = {'convert': [[64,256,512,1024,2048],[128,256,256,512,512]], 'deep_pool': [[512, 512, 256, 256, 128], [512, 256, 256, 128, 128], [False, True, True, True, False], [True, True, True, True, False]], 'score': 128}\n",
        "\n",
        "class ConvertLayer(nn.Module):\n",
        "    def __init__(self, list_k):\n",
        "        super(ConvertLayer, self).__init__()\n",
        "        up = []\n",
        "        for i in range(len(list_k[0])):\n",
        "            up.append(nn.Sequential(nn.Conv2d(list_k[0][i], list_k[1][i], 1, 1, bias=False), nn.ReLU(inplace=True)))\n",
        "        self.convert0 = nn.ModuleList(up)\n",
        "\n",
        "    def forward(self, list_x):\n",
        "        resl = []\n",
        "        for i in range(len(list_x)):\n",
        "            resl.append(self.convert0[i](list_x[i]))\n",
        "        return resl\n",
        "\n",
        "class DeepPoolLayer(nn.Module):\n",
        "    def __init__(self, k, k_out, need_x2, need_fuse):\n",
        "        super(DeepPoolLayer, self).__init__()\n",
        "        self.pools_sizes = [2,4,8]\n",
        "        self.need_x2 = need_x2\n",
        "        self.need_fuse = need_fuse\n",
        "        pools, convs = [],[]\n",
        "        for i in self.pools_sizes:\n",
        "            pools.append(nn.AvgPool2d(kernel_size=i, stride=i))\n",
        "            convs.append(nn.Conv2d(k, k, 3, 1, 1, bias=False))\n",
        "        self.pools = nn.ModuleList(pools)\n",
        "        self.convs = nn.ModuleList(convs)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv_sum = nn.Conv2d(k, k_out, 3, 1, 1, bias=False)\n",
        "        if self.need_fuse:\n",
        "            self.conv_sum_c = nn.Conv2d(k_out, k_out, 3, 1, 1, bias=False)\n",
        "\n",
        "    def forward(self, x, x2=None, x3=None):\n",
        "        x_size = x.size()\n",
        "        resl = x\n",
        "        for i in range(len(self.pools_sizes)):\n",
        "            y = self.convs[i](self.pools[i](x))\n",
        "            resl = torch.add(resl, F.interpolate(y, x_size[2:], mode='bilinear', align_corners=True))\n",
        "        resl = self.relu(resl)\n",
        "        if self.need_x2:\n",
        "            resl = F.interpolate(resl, x2.size()[2:], mode='bilinear', align_corners=True)\n",
        "        resl = self.conv_sum(resl)\n",
        "        if self.need_fuse:\n",
        "            resl = self.conv_sum_c(torch.add(torch.add(resl, x2), x3))\n",
        "        return resl\n",
        "\n",
        "class ScoreLayer(nn.Module):\n",
        "    def __init__(self, k):\n",
        "        super(ScoreLayer, self).__init__()\n",
        "        self.score = nn.Conv2d(k ,1, 1, 1)\n",
        "\n",
        "    def forward(self, x, x_size=None):\n",
        "        x = self.score(x)\n",
        "        if x_size is not None:\n",
        "            x = F.interpolate(x, x_size[2:], mode='bilinear', align_corners=True)\n",
        "        return x\n",
        "\n",
        "def extra_layer(base_model_cfg, vgg):\n",
        "    if base_model_cfg == 'vgg':\n",
        "        config = config_vgg\n",
        "    elif base_model_cfg == 'resnet':\n",
        "        config = config_resnet\n",
        "    convert_layers, deep_pool_layers, score_layers = [], [], []\n",
        "    convert_layers = ConvertLayer(config['convert'])\n",
        "\n",
        "    for i in range(len(config['deep_pool'][0])):\n",
        "        deep_pool_layers += [DeepPoolLayer(config['deep_pool'][0][i], config['deep_pool'][1][i], config['deep_pool'][2][i], config['deep_pool'][3][i])]\n",
        "\n",
        "    score_layers = ScoreLayer(config['score'])\n",
        "\n",
        "    return vgg, convert_layers, deep_pool_layers, score_layers\n",
        "\n",
        "\n",
        "class PoolNet(nn.Module):\n",
        "    def __init__(self, base_model_cfg, base, convert_layers, deep_pool_layers, score_layers):\n",
        "        super(PoolNet, self).__init__()\n",
        "        self.base_model_cfg = base_model_cfg\n",
        "        self.base = base\n",
        "        self.deep_pool = nn.ModuleList(deep_pool_layers)\n",
        "        self.score = score_layers\n",
        "        if self.base_model_cfg == 'resnet':\n",
        "            self.convert = convert_layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_size = x.size()\n",
        "        conv2merge, infos = self.base(x)\n",
        "        if self.base_model_cfg == 'resnet':\n",
        "            conv2merge = self.convert(conv2merge)\n",
        "        conv2merge = conv2merge[::-1]\n",
        "\n",
        "        edge_merge = []\n",
        "        merge = self.deep_pool[0](conv2merge[0], conv2merge[1], infos[0])\n",
        "        for k in range(1, len(conv2merge)-1):\n",
        "            merge = self.deep_pool[k](merge, conv2merge[k+1], infos[k])\n",
        "\n",
        "        merge = self.deep_pool[-1](merge)\n",
        "        merge = self.score(merge, x_size)\n",
        "        return merge\n",
        "\n",
        "def build_model(base_model_cfg='vgg'):\n",
        "    if base_model_cfg == 'vgg':\n",
        "        return PoolNet(base_model_cfg, *extra_layer(base_model_cfg, vgg16_locate()))\n",
        "    elif base_model_cfg == 'resnet':\n",
        "        return PoolNet(base_model_cfg, *extra_layer(base_model_cfg, resnet50_locate()))\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(0, 0.01)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n",
        "\n",
        "full_PN_model = build_model('resnet')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/quantization/observer.py:136: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
            "  Returning default scale and zero point \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-ua41iO5qs1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "797d2cb7-389c-4c4d-b881-41f1ac5bd1e6"
      },
      "source": [
        "\n",
        "torch.save(full_PN_model.state_dict(), 'test2.pth')\n",
        "full_PN_model.eval()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PoolNet(\n",
              "  (base): ResNet_locate(\n",
              "    (resnet): QuantizableResNet(\n",
              "      (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=1.0, zero_point=0, padding=(3, 3))\n",
              "      (bn1): Identity()\n",
              "      (relu): Identity()\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
              "      (layer1): Sequential(\n",
              "        (0): QuantizableBottleneck(\n",
              "          (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn1): Identity()\n",
              "          (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "          (bn2): Identity()\n",
              "          (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn3): Identity()\n",
              "          (relu): QuantizedReLU()\n",
              "          (downsample): Sequential(\n",
              "            (0): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "            (1): Identity()\n",
              "          )\n",
              "          (skip_add_relu): QFunctional(\n",
              "            scale=1.0, zero_point=0\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "          (relu1): Identity()\n",
              "          (relu2): Identity()\n",
              "        )\n",
              "        (1): QuantizableBottleneck(\n",
              "          (conv1): QuantizedConvReLU2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn1): Identity()\n",
              "          (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "          (bn2): Identity()\n",
              "          (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn3): Identity()\n",
              "          (relu): QuantizedReLU()\n",
              "          (skip_add_relu): QFunctional(\n",
              "            scale=1.0, zero_point=0\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "          (relu1): Identity()\n",
              "          (relu2): Identity()\n",
              "        )\n",
              "        (2): QuantizableBottleneck(\n",
              "          (conv1): QuantizedConvReLU2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn1): Identity()\n",
              "          (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "          (bn2): Identity()\n",
              "          (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn3): Identity()\n",
              "          (relu): QuantizedReLU()\n",
              "          (skip_add_relu): QFunctional(\n",
              "            scale=1.0, zero_point=0\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "          (relu1): Identity()\n",
              "          (relu2): Identity()\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): QuantizableBottleneck(\n",
              "          (conv1): QuantizedConvReLU2d(256, 128, kernel_size=(1, 1), stride=(2, 2), scale=1.0, zero_point=0)\n",
              "          (bn1): Identity()\n",
              "          (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "          (bn2): Identity()\n",
              "          (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn3): Identity()\n",
              "          (relu): QuantizedReLU()\n",
              "          (downsample): Sequential(\n",
              "            (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=1.0, zero_point=0)\n",
              "            (1): Identity()\n",
              "          )\n",
              "          (skip_add_relu): QFunctional(\n",
              "            scale=1.0, zero_point=0\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "          (relu1): Identity()\n",
              "          (relu2): Identity()\n",
              "        )\n",
              "        (1): QuantizableBottleneck(\n",
              "          (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn1): Identity()\n",
              "          (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "          (bn2): Identity()\n",
              "          (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn3): Identity()\n",
              "          (relu): QuantizedReLU()\n",
              "          (skip_add_relu): QFunctional(\n",
              "            scale=1.0, zero_point=0\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "          (relu1): Identity()\n",
              "          (relu2): Identity()\n",
              "        )\n",
              "        (2): QuantizableBottleneck(\n",
              "          (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn1): Identity()\n",
              "          (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "          (bn2): Identity()\n",
              "          (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn3): Identity()\n",
              "          (relu): QuantizedReLU()\n",
              "          (skip_add_relu): QFunctional(\n",
              "            scale=1.0, zero_point=0\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "          (relu1): Identity()\n",
              "          (relu2): Identity()\n",
              "        )\n",
              "        (3): QuantizableBottleneck(\n",
              "          (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn1): Identity()\n",
              "          (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "          (bn2): Identity()\n",
              "          (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn3): Identity()\n",
              "          (relu): QuantizedReLU()\n",
              "          (skip_add_relu): QFunctional(\n",
              "            scale=1.0, zero_point=0\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "          (relu1): Identity()\n",
              "          (relu2): Identity()\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): QuantizableBottleneck(\n",
              "          (conv1): QuantizedConvReLU2d(512, 256, kernel_size=(1, 1), stride=(2, 2), scale=1.0, zero_point=0)\n",
              "          (bn1): Identity()\n",
              "          (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "          (bn2): Identity()\n",
              "          (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn3): Identity()\n",
              "          (relu): QuantizedReLU()\n",
              "          (downsample): Sequential(\n",
              "            (0): QuantizedConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), scale=1.0, zero_point=0)\n",
              "            (1): Identity()\n",
              "          )\n",
              "          (skip_add_relu): QFunctional(\n",
              "            scale=1.0, zero_point=0\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "          (relu1): Identity()\n",
              "          (relu2): Identity()\n",
              "        )\n",
              "        (1): QuantizableBottleneck(\n",
              "          (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn1): Identity()\n",
              "          (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "          (bn2): Identity()\n",
              "          (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn3): Identity()\n",
              "          (relu): QuantizedReLU()\n",
              "          (skip_add_relu): QFunctional(\n",
              "            scale=1.0, zero_point=0\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "          (relu1): Identity()\n",
              "          (relu2): Identity()\n",
              "        )\n",
              "        (2): QuantizableBottleneck(\n",
              "          (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn1): Identity()\n",
              "          (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "          (bn2): Identity()\n",
              "          (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn3): Identity()\n",
              "          (relu): QuantizedReLU()\n",
              "          (skip_add_relu): QFunctional(\n",
              "            scale=1.0, zero_point=0\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "          (relu1): Identity()\n",
              "          (relu2): Identity()\n",
              "        )\n",
              "        (3): QuantizableBottleneck(\n",
              "          (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn1): Identity()\n",
              "          (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "          (bn2): Identity()\n",
              "          (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn3): Identity()\n",
              "          (relu): QuantizedReLU()\n",
              "          (skip_add_relu): QFunctional(\n",
              "            scale=1.0, zero_point=0\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "          (relu1): Identity()\n",
              "          (relu2): Identity()\n",
              "        )\n",
              "        (4): QuantizableBottleneck(\n",
              "          (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn1): Identity()\n",
              "          (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "          (bn2): Identity()\n",
              "          (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn3): Identity()\n",
              "          (relu): QuantizedReLU()\n",
              "          (skip_add_relu): QFunctional(\n",
              "            scale=1.0, zero_point=0\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "          (relu1): Identity()\n",
              "          (relu2): Identity()\n",
              "        )\n",
              "        (5): QuantizableBottleneck(\n",
              "          (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn1): Identity()\n",
              "          (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(1, 1))\n",
              "          (bn2): Identity()\n",
              "          (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn3): Identity()\n",
              "          (relu): QuantizedReLU()\n",
              "          (skip_add_relu): QFunctional(\n",
              "            scale=1.0, zero_point=0\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "          (relu1): Identity()\n",
              "          (relu2): Identity()\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): QuantizableBottleneck(\n",
              "          (conv1): QuantizedConvReLU2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn1): Identity()\n",
              "          (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(2, 2), dilation=(2, 2))\n",
              "          (bn2): Identity()\n",
              "          (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn3): Identity()\n",
              "          (relu): QuantizedReLU()\n",
              "          (downsample): Sequential(\n",
              "            (0): QuantizedConv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "            (1): Identity()\n",
              "          )\n",
              "          (skip_add_relu): QFunctional(\n",
              "            scale=1.0, zero_point=0\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "          (relu1): Identity()\n",
              "          (relu2): Identity()\n",
              "        )\n",
              "        (1): QuantizableBottleneck(\n",
              "          (conv1): QuantizedConvReLU2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn1): Identity()\n",
              "          (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(2, 2), dilation=(2, 2))\n",
              "          (bn2): Identity()\n",
              "          (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn3): Identity()\n",
              "          (relu): QuantizedReLU()\n",
              "          (skip_add_relu): QFunctional(\n",
              "            scale=1.0, zero_point=0\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "          (relu1): Identity()\n",
              "          (relu2): Identity()\n",
              "        )\n",
              "        (2): QuantizableBottleneck(\n",
              "          (conv1): QuantizedConvReLU2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn1): Identity()\n",
              "          (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0, zero_point=0, padding=(2, 2), dilation=(2, 2))\n",
              "          (bn2): Identity()\n",
              "          (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=1.0, zero_point=0)\n",
              "          (bn3): Identity()\n",
              "          (relu): QuantizedReLU()\n",
              "          (skip_add_relu): QFunctional(\n",
              "            scale=1.0, zero_point=0\n",
              "            (activation_post_process): Identity()\n",
              "          )\n",
              "          (relu1): Identity()\n",
              "          (relu2): Identity()\n",
              "        )\n",
              "      )\n",
              "      (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "      (dequant): DeQuantize()\n",
              "    )\n",
              "    (ppms_pre): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (ppms): ModuleList(\n",
              "      (0): Sequential(\n",
              "        (0): AdaptiveAvgPool2d(output_size=1)\n",
              "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): AdaptiveAvgPool2d(output_size=3)\n",
              "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): AdaptiveAvgPool2d(output_size=5)\n",
              "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (ppm_cat): Sequential(\n",
              "      (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (infos): ModuleList(\n",
              "      (0): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (deep_pool): ModuleList(\n",
              "    (0): DeepPoolLayer(\n",
              "      (pools): ModuleList(\n",
              "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "        (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
              "        (2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
              "      )\n",
              "      (convs): ModuleList(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "      (conv_sum): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (conv_sum_c): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "    (1): DeepPoolLayer(\n",
              "      (pools): ModuleList(\n",
              "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "        (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
              "        (2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
              "      )\n",
              "      (convs): ModuleList(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "      (conv_sum): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (conv_sum_c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "    (2): DeepPoolLayer(\n",
              "      (pools): ModuleList(\n",
              "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "        (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
              "        (2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
              "      )\n",
              "      (convs): ModuleList(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "      (conv_sum): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (conv_sum_c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "    (3): DeepPoolLayer(\n",
              "      (pools): ModuleList(\n",
              "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "        (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
              "        (2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
              "      )\n",
              "      (convs): ModuleList(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "      (conv_sum): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (conv_sum_c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "    (4): DeepPoolLayer(\n",
              "      (pools): ModuleList(\n",
              "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "        (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
              "        (2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
              "      )\n",
              "      (convs): ModuleList(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "      (conv_sum): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "  )\n",
              "  (score): ScoreLayer(\n",
              "    (score): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (convert): ConvertLayer(\n",
              "    (convert0): ModuleList(\n",
              "      (0): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vL0kT-8m-rRH",
        "colab_type": "text"
      },
      "source": [
        "### PoolNet Quantization try"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u7mxYdDgRjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "3dd6157e-7253-4e2d-d3b1-78541f2fc8ea"
      },
      "source": [
        "from torch.quantization import convert\n",
        "model_ft_tuned.cpu()\n",
        "\n",
        "model_quantized_and_trained = convert(model_ft_tuned, inplace=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-5012c12e5adb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_ft_tuned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_quantized_and_trained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft_tuned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_ft_tuned' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa8uxmUhIfVc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "86e20a09-0ec1-40e2-bb61-3e64496da29f"
      },
      "source": [
        "from torch.quantization import QuantStub, DeQuantStub, fuse_modules\n",
        "import torchvision.models.quantization as models\n",
        "\n",
        "#full_PN_model = models.resnet18(pretrained=True, progress=True, quantize=False)\n",
        "\n",
        "full_PN_model.eval()\n",
        "\n",
        "# Fuse Conv, bn and relu\n",
        "full_PN_model.fuse_model()\n",
        "\n",
        "# set quantization config for server (x86)\n",
        "full_PN_model.qconfig = torch.quantization.default_qat_qconfig\n",
        "\n",
        "# insert observers\n",
        "torch.quantization.prepare(full_PN_model, inplace=True)\n",
        "# Calibrate the model and collect statistics\n",
        "\n",
        "# convert to quantized version\n",
        "torch.quantization.convert(full_PN_model, inplace=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleAttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-04a37fcd9e81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Fuse Conv, bn and relu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mfull_PN_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuse_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# set quantization config for server (x86)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    770\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 772\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleAttributeError\u001b[0m: 'PoolNet' object has no attribute 'fuse_model'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hNzM2mytc84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/drive/My Drive/Colab Notebooks/models/final.pth' /content\n",
        "!cp '/content/drive/My Drive/Colab Notebooks/models/final (2).pth' /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qte2W3V4Tvxt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7c86a75-d27a-47d8-c295-75481a57b58e"
      },
      "source": [
        "from torch.quantization import QuantStub, DeQuantStub, fuse_modules\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(device='cuda')\n",
        "else:\n",
        "    device = torch.device(device='cpu')\n",
        "# Load model\n",
        "\n",
        "full_PN_model.load_state_dict(torch.load('/content/final.pth', map_location=device))\n",
        "full_PN_model.to(device)\n",
        "full_PN_model.eval()\n",
        "\n",
        "full_PN_model = fuse_modules(full_PN_model,[['convs','bn1','relu']])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PoolNet(\n",
              "  (base): ResNet_locate(\n",
              "    (resnet): ResNet(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
              "      (layer1): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (3): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (4): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (5): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): Bottleneck(\n",
              "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (2): Bottleneck(\n",
              "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ppms_pre): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (ppms): ModuleList(\n",
              "      (0): Sequential(\n",
              "        (0): AdaptiveAvgPool2d(output_size=1)\n",
              "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): AdaptiveAvgPool2d(output_size=3)\n",
              "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): AdaptiveAvgPool2d(output_size=5)\n",
              "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (2): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (ppm_cat): Sequential(\n",
              "      (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): ReLU(inplace=True)\n",
              "    )\n",
              "    (infos): ModuleList(\n",
              "      (0): Sequential(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (deep_pool): ModuleList(\n",
              "    (0): DeepPoolLayer(\n",
              "      (pools): ModuleList(\n",
              "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "        (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
              "        (2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
              "      )\n",
              "      (convs): ModuleList(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "      (conv_sum): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (conv_sum_c): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "    (1): DeepPoolLayer(\n",
              "      (pools): ModuleList(\n",
              "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "        (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
              "        (2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
              "      )\n",
              "      (convs): ModuleList(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "      (conv_sum): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (conv_sum_c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "    (2): DeepPoolLayer(\n",
              "      (pools): ModuleList(\n",
              "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "        (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
              "        (2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
              "      )\n",
              "      (convs): ModuleList(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "      (conv_sum): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (conv_sum_c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "    (3): DeepPoolLayer(\n",
              "      (pools): ModuleList(\n",
              "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "        (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
              "        (2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
              "      )\n",
              "      (convs): ModuleList(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "      (conv_sum): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (conv_sum_c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "    (4): DeepPoolLayer(\n",
              "      (pools): ModuleList(\n",
              "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "        (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
              "        (2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
              "      )\n",
              "      (convs): ModuleList(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      )\n",
              "      (relu): ReLU()\n",
              "      (conv_sum): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "  )\n",
              "  (score): ScoreLayer(\n",
              "    (score): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (convert): ConvertLayer(\n",
              "    (convert0): ModuleList(\n",
              "      (0): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MOZTQc-Ap-O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "05c98979-f4a1-495f-94bb-017d58530a5c"
      },
      "source": [
        "import torch\n",
        "full_PN_model = full_PN_model.load_state_dict(torch.load('final.pth'))\n",
        "print(full_PN_model)\n",
        "full_PN_model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-ddd9a4a37275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfull_PN_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_PN_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_PN_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfull_PN_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'final.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DamEr2zXBImh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e3ff74a-4755-4f12-ecbc-77e9385c9b1b"
      },
      "source": [
        "import torch\n",
        "#torch.quantization.quantize(full_PN_model, run_fn, run_args, mapping=None, inplace=False)\n",
        "print(full_PN_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PoolNet(\n",
            "  (base): ResNet_locate(\n",
            "    (resnet): ResNet(\n",
            "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
            "      (layer1): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer2): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer3): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (layer4): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ppms_pre): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (ppms): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=1)\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=3)\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=5)\n",
            "        (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (2): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (ppm_cat): Sequential(\n",
            "      (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): ReLU(inplace=True)\n",
            "    )\n",
            "    (infos): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (deep_pool): ModuleList(\n",
            "    (0): DeepPoolLayer(\n",
            "      (pools): ModuleList(\n",
            "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "        (2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "      )\n",
            "      (convs): ModuleList(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (relu): ReLU()\n",
            "      (conv_sum): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (conv_sum_c): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (1): DeepPoolLayer(\n",
            "      (pools): ModuleList(\n",
            "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "        (2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "      )\n",
            "      (convs): ModuleList(\n",
            "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (relu): ReLU()\n",
            "      (conv_sum): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (conv_sum_c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (2): DeepPoolLayer(\n",
            "      (pools): ModuleList(\n",
            "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "        (2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "      )\n",
            "      (convs): ModuleList(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (relu): ReLU()\n",
            "      (conv_sum): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (conv_sum_c): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (3): DeepPoolLayer(\n",
            "      (pools): ModuleList(\n",
            "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "        (2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "      )\n",
            "      (convs): ModuleList(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (relu): ReLU()\n",
            "      (conv_sum): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (conv_sum_c): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (4): DeepPoolLayer(\n",
            "      (pools): ModuleList(\n",
            "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "        (1): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
            "        (2): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
            "      )\n",
            "      (convs): ModuleList(\n",
            "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (relu): ReLU()\n",
            "      (conv_sum): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "  )\n",
            "  (score): ScoreLayer(\n",
            "    (score): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (convert): ConvertLayer(\n",
            "    (convert0): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Sequential(\n",
            "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeBSPU79qeQa",
        "colab_type": "text"
      },
      "source": [
        "### ResNet50 Quantization model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQ55XWZK-oFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision.models.resnet import Bottleneck, BasicBlock, ResNet, model_urls\n",
        "import torch.nn as nn\n",
        "from torchvision.models.utils import load_state_dict_from_url\n",
        "from torch.quantization import QuantStub, DeQuantStub, fuse_modules\n",
        "from torch._jit_internal import Optional\n",
        "from torchvision.models.quantization.utils import _replace_relu, quantize_model\n",
        "\n",
        "__all__ = ['QuantizableResNet', 'resnet18', 'resnet50',\n",
        "           'resnext101_32x8d']\n",
        "\n",
        "\n",
        "quant_model_urls = {\n",
        "    'resnet18_fbgemm':\n",
        "        'https://download.pytorch.org/models/quantized/resnet18_fbgemm_16fa66dd.pth',\n",
        "    'resnet50_fbgemm':\n",
        "        'https://download.pytorch.org/models/quantized/resnet50_fbgemm_bf931d71.pth',\n",
        "    'resnext101_32x8d_fbgemm':\n",
        "        'https://download.pytorch.org/models/quantized/resnext101_32x8_fbgemm_09835ccf.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class QuantizableBasicBlock(BasicBlock):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(QuantizableBasicBlock, self).__init__(*args, **kwargs)\n",
        "        self.add_relu = torch.nn.quantized.FloatFunctional()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.add_relu.add_relu(out, identity)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def fuse_model(self):\n",
        "        torch.quantization.fuse_modules(self, [['conv1', 'bn1', 'relu'],\n",
        "                                               ['conv2', 'bn2']], inplace=True)\n",
        "        if self.downsample:\n",
        "            torch.quantization.fuse_modules(self.downsample, ['0', '1'], inplace=True)\n",
        "\n",
        "\n",
        "class QuantizableBottleneck(Bottleneck):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(QuantizableBottleneck, self).__init__(*args, **kwargs)\n",
        "        self.skip_add_relu = nn.quantized.FloatFunctional()\n",
        "        self.relu1 = nn.ReLU(inplace=False)\n",
        "        self.relu2 = nn.ReLU(inplace=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out = self.skip_add_relu.add_relu(out, identity)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def fuse_model(self):\n",
        "        fuse_modules(self, [['conv1', 'bn1', 'relu1'],\n",
        "                            ['conv2', 'bn2', 'relu2'],\n",
        "                            ['conv3', 'bn3']], inplace=True)\n",
        "        if self.downsample:\n",
        "            torch.quantization.fuse_modules(self.downsample, ['0', '1'], inplace=True)\n",
        "\n",
        "\n",
        "class QuantizableResNet(ResNet):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(QuantizableResNet, self).__init__(*args, **kwargs)\n",
        "\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        # Ensure scriptability\n",
        "        # super(QuantizableResNet,self).forward(x)\n",
        "        # is not scriptable\n",
        "        x = self._forward_impl(x)\n",
        "        x = self.dequant(x)\n",
        "        return x\n",
        "\n",
        "    def fuse_model(self):\n",
        "        r\"\"\"Fuse conv/bn/relu modules in resnet models\n",
        "        Fuse conv+bn+relu/ Conv+relu/conv+Bn modules to prepare for quantization.\n",
        "        Model is modified in place.  Note that this operation does not change numerics\n",
        "        and the model after modification is in floating point\n",
        "        \"\"\"\n",
        "\n",
        "        fuse_modules(self, ['conv1', 'bn1', 'relu'], inplace=True)\n",
        "        for m in self.modules():\n",
        "            if type(m) == QuantizableBottleneck or type(m) == QuantizableBasicBlock:\n",
        "                m.fuse_model()\n",
        "\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, quantize, **kwargs):\n",
        "    model = QuantizableResNet(block, layers, **kwargs)\n",
        "    _replace_relu(model)\n",
        "    if quantize:\n",
        "        # TODO use pretrained as a string to specify the backend\n",
        "        backend = 'fbgemm'\n",
        "        quantize_model(model, backend)\n",
        "    else:\n",
        "        assert pretrained in [True, False]\n",
        "\n",
        "    if pretrained:\n",
        "        if quantize:\n",
        "            model_url = quant_model_urls[arch + '_' + backend]\n",
        "        else:\n",
        "            model_url = model_urls[arch]\n",
        "\n",
        "        state_dict = load_state_dict_from_url(model_url,\n",
        "                                              progress=progress)\n",
        "\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "def resnet50(pretrained=False, progress=True, quantize=True, **kwargs):\n",
        "    r\"\"\"ResNet-50 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet50', QuantizableBottleneck, [3, 4, 6, 3], pretrained, progress,\n",
        "                   quantize, **kwargs)\n",
        "    \n",
        "modelQ = resnet50()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osq8VHox8SLI",
        "colab_type": "text"
      },
      "source": [
        "### PoolNet Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MIZCNCR0cGuN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "04b63785-a665-4292-b85e-7b249da43e5d"
      },
      "source": [
        "import torch\n",
        "model = model.load_state_dict(torch.load('final.pth'))\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-671bfee4ab01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJgqrdkXkGud",
        "colab_type": "text"
      },
      "source": [
        "#try pyramid\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgcBad4ZkNXe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "553c6150-db47-4000-f259-bf816b1a1ad0"
      },
      "source": [
        "!git clone https://github.com/parth15041995/Pyramid-SD_PyTorch.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Pyramid-SD_PyTorch'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (79/79), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 79 (delta 24), reused 27 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (79/79), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMQ3tmIWm3H1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4abde3f-1623-4f3a-d11f-6dccee4d0e56"
      },
      "source": [
        "cd /content/Pyramid-SD_PyTorch "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Pyramid-SD_PyTorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg8W721VmjkD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "371ccd5f898f4f309a4df5f942748de6",
            "654007f5de0c4bcdb6c59f19bb72939a",
            "0b67cd760a7f42038299b0d30377e8b2",
            "f04776ca19d645f3b66cc2884f4a1f21",
            "7c7ee7239c6d46e694299b1323af9182",
            "5b2c759e8961470c8361168b4d408fb5",
            "f4e0233d03fe4bb185b0f90fd720fa65",
            "09fa8e467ac9448a9508065693799d80"
          ]
        },
        "outputId": "1b23ca3c-dfc7-44a1-d784-09d0899ef4bb"
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "\n",
        "import argparse\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from src.model import SODModel\n",
        "from src.dataloader import InfDataloader, SODLoader\n",
        "model = SODModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "371ccd5f898f4f309a4df5f942748de6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eywKqVXngdH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "aed1dfda-768f-4a94-a7f9-474f50a29582"
      },
      "source": [
        "#model.load_state_dict(torch.load('/content/drive/My Drive/best-model_epoch-204_mae-0.0505_loss-0.1370.pth'))\n",
        "torch.quantization.quantize(model, run_fn, run_args, mapping=None, inplace=False)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-ffb01de5b01d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model.load_state_dict(torch.load('/content/drive/My Drive/best-model_epoch-204_mae-0.0505_loss-0.1370.pth'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'run_fn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgju-aiHwdLR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "71e65512-71be-4320-f961-6e9a8f1b243a"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(device='cuda')\n",
        "else:\n",
        "    device = torch.device(device='cpu')\n",
        "# Load model\n",
        "model = SODModel()\n",
        "chkpt = torch.load('/content/drive/My Drive/best-model_epoch-204_mae-0.0505_loss-0.1370.pth', map_location=device)\n",
        "model.load_state_dict(chkpt['model'])\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "model = model.fuse_modules()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleAttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c7c443179edc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuse_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    770\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 772\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleAttributeError\u001b[0m: 'SODModel' object has no attribute 'fuse_modules'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7ASePasod_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "385c892f-b126-4fdd-aa90-07411522573d"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SODModel(\n",
              "  (vgg16): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (cpfe_conv3_3): CPFE(\n",
              "    (conv_1_1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (conv_dil_3): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3), bias=False)\n",
              "    (conv_dil_5): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(5, 5), dilation=(5, 5), bias=False)\n",
              "    (conv_dil_7): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(7, 7), dilation=(7, 7), bias=False)\n",
              "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (cpfe_conv4_3): CPFE(\n",
              "    (conv_1_1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (conv_dil_3): Conv2d(512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3), bias=False)\n",
              "    (conv_dil_5): Conv2d(512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(5, 5), dilation=(5, 5), bias=False)\n",
              "    (conv_dil_7): Conv2d(512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(7, 7), dilation=(7, 7), bias=False)\n",
              "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (cpfe_conv5_3): CPFE(\n",
              "    (conv_1_1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (conv_dil_3): Conv2d(512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3), bias=False)\n",
              "    (conv_dil_5): Conv2d(512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(5, 5), dilation=(5, 5), bias=False)\n",
              "    (conv_dil_7): Conv2d(512, 32, kernel_size=(3, 3), stride=(1, 1), padding=(7, 7), dilation=(7, 7), bias=False)\n",
              "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (cha_att): ChannelwiseAttention(\n",
              "    (linear_1): Linear(in_features=384, out_features=96, bias=True)\n",
              "    (linear_2): Linear(in_features=96, out_features=384, bias=True)\n",
              "  )\n",
              "  (hl_conv1): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (hl_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (ll_conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (ll_bn_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (ll_conv_2): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (ll_bn_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (ll_conv_3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (ll_bn_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (spa_att): SpatialAttention(\n",
              "    (grp1_conv1k): Conv2d(64, 32, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n",
              "    (grp1_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (grp1_convk1): Conv2d(32, 1, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n",
              "    (grp1_bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (grp2_convk1): Conv2d(64, 32, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0))\n",
              "    (grp2_bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (grp2_conv1k): Conv2d(32, 1, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n",
              "    (grp2_bn2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (ff_conv_1): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    }
  ]
}