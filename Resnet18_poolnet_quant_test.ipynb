{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet18/poolnet quant test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "dvcUjRd4m0ws",
        "cwKosoW5TF7G",
        "Kf3fCQZGm9kH",
        "GZDeNpgKJPnx",
        "KG3-khvm0Mi2",
        "Vjln9dS90QTy",
        "BAh0tdBUS_W-",
        "HOL7u2GfTTQM"
      ],
      "toc_visible": true,
      "mount_file_id": "1SFLlCs3Bl2J7HB-QfCwFYK50YCVEsVg2",
      "authorship_tag": "ABX9TyPNbwhvjpVxDntPDGqeVKO4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParthPatel-ES/PoolNet/blob/master/Resnet18_poolnet_quant_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvcUjRd4m0ws",
        "colab_type": "text"
      },
      "source": [
        "### torch_nightly install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNyQYNhnrW21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "5af4df01-1b02-4412-db11-78e50da34174"
      },
      "source": [
        "!yes y | pip uninstall torch torchvision\n",
        "!yes y | pip install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling torch-1.6.0+cu101:\n",
            "  Would remove:\n",
            "    /usr/local/bin/convert-caffe2-to-onnx\n",
            "    /usr/local/bin/convert-onnx-to-caffe2\n",
            "    /usr/local/lib/python3.6/dist-packages/caffe2/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torch-1.6.0+cu101.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/*\n",
            "Proceed (y/n)? n\n",
            "  Successfully uninstalled torch-1.6.0+cu101\n",
            "Uninstalling torchvision-0.7.0+cu101:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision-0.7.0+cu101.dist-info/*\n",
            "    /usr/local/lib/python3.6/dist-packages/torchvision/*\n",
            "Proceed (y/n)?   Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Looking in links: https://download.pytorch.org/whl/nightly/cu101/torch_nightly.html\n",
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/nightly/cu101/torch-1.7.0.dev20200901%2Bcu101-cp36-cp36m-linux_x86_64.whl (849.9MB)\n",
            "\u001b[K     |████▎                           | 112.6MB 1.4MB/s eta 0:09:05"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwKosoW5TF7G",
        "colab_type": "text"
      },
      "source": [
        "### Initial setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_giwdyRJPna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsnBDdbpJPnk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "85c798eb-571d-40b1-8f6a-10c452070298"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "import torch.quantization\n",
        "\n",
        "# # Setup warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\n",
        "    action='ignore',\n",
        "    category=DeprecationWarning,\n",
        "    module=r'.*'\n",
        ")\n",
        "warnings.filterwarnings(\n",
        "    action='default',\n",
        "    module=r'torch.quantization'\n",
        ")\n",
        "\n",
        "# Specify random seed for repeatable results\n",
        "torch.manual_seed(191009)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f1cc9df7240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59YjZhjVkidC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp '/content/drive/My Drive/DUTS.zip' /content"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bMh9_9bSwAzI",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import zipfile\n",
        "\n",
        "url = 'https://s3.amazonaws.com/pytorch-tutorial-assets/imagenet_1k.zip'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "\n",
        "open('imagenet_1k.zip', 'wb').write(r.content)\n",
        "\n",
        "with zipfile.ZipFile('/content/imagenet_1k.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./data')\n",
        "\n",
        "with zipfile.ZipFile('DUTS.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./data0')    "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kf3fCQZGm9kH",
        "colab_type": "text"
      },
      "source": [
        "### Dataset and Resnet18 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-KGyInjXnT1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c0060aa6-deaa-4307-f194-6ebf97448736"
      },
      "source": [
        "import requests\n",
        "import zipfile\n",
        "\n",
        "url = 'https://s3.amazonaws.com/pytorch-tutorial-assets/imagenet_1k.zip'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "\n",
        "open('imagenet_1k.zip', 'wb').write(r.content)\n",
        "\n",
        "with zipfile.ZipFile('/content/imagenet_1k.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./data')\n",
        "\n",
        "url = 'https://download.pytorch.org/models/quantized/resnet18_fbgemm_16fa66dd.pth'\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "\n",
        "open('./data/resnet18_pretrained_float.pth', 'wb').write(r.content)\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11783981"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZDeNpgKJPnx",
        "colab_type": "text"
      },
      "source": [
        "### 2. Helper functions\n",
        "-------------------\n",
        "\n",
        "We next define several helper functions to help with model evaluation. These mostly come from\n",
        "`here <https://github.com/pytorch/examples/blob/master/imagenet/main.py>`_.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MJxhIFRJPny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "\n",
        "def evaluate(model, criterion, data_loader, neval_batches):\n",
        "    model.eval()\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        for image, target in data_loader:\n",
        "            output = model(image)\n",
        "            loss = criterion(output, target)\n",
        "            cnt += 1\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "            print('.', end = '')\n",
        "            top1.update(acc1[0], image.size(0))\n",
        "            top5.update(acc5[0], image.size(0))\n",
        "            if cnt >= neval_batches:\n",
        "                 return top1, top5\n",
        "\n",
        "    return top1, top5\n",
        "\n",
        "def load_model(model_file):\n",
        "    model = MobileNetV2()\n",
        "    state_dict = torch.load(model_file)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.to('cpu')\n",
        "    return model\n",
        "\n",
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "    os.remove('temp.p')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icy_AEpSUJXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data_loaders(data_path):\n",
        "\n",
        "    traindir = os.path.join(data_path, 'train')\n",
        "    valdir = os.path.join(data_path, 'val')\n",
        "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    dataset = torchvision.datasets.ImageFolder(\n",
        "        traindir,\n",
        "        transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]))\n",
        "\n",
        "    dataset_test = torchvision.datasets.ImageFolder(\n",
        "        valdir,\n",
        "        transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ]))\n",
        "\n",
        "    train_sampler = torch.utils.data.RandomSampler(dataset)\n",
        "    test_sampler = torch.utils.data.SequentialSampler(dataset_test)\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, batch_size=train_batch_size,\n",
        "        sampler=train_sampler)\n",
        "\n",
        "    data_loader_test = torch.utils.data.DataLoader(\n",
        "        dataset_test, batch_size=eval_batch_size,\n",
        "        sampler=test_sampler)\n",
        "\n",
        "    return data_loader, data_loader_test"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sks-K-7OJPoF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/data/imagenet_1k'\n",
        "saved_model_dir = 'data/'\n",
        "float_model_file = 'test.pth' # 'mobilenet_pretrained_float.pth' #\n",
        "scripted_float_model_file = 'resnet_quantization_scripted.pth'\n",
        "scripted_quantized_model_file = 'resnet_quantization_scripted_quantized.pth'\n",
        "\n",
        "train_batch_size = 30\n",
        "eval_batch_size = 30\n",
        "\n",
        "data_loader, data_loader_test = prepare_data_loaders(data_path)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#float_model = load_model(saved_model_dir + float_model_file).to('cpu')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUkj9GW7nEAs",
        "colab_type": "text"
      },
      "source": [
        "## Your model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG3-khvm0Mi2",
        "colab_type": "text"
      },
      "source": [
        "### Resnet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq2LY_dLNsLM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "affine_par = True\n",
        "import torch.nn as nn\n",
        "from torchvision.models.utils import load_state_dict_from_url\n",
        "from torch.quantization import QuantStub, DeQuantStub, fuse_modules\n",
        "from torch._jit_internal import Optional\n",
        "from torchvision.models.quantization.utils import _replace_relu, quantize_model\n",
        "\n",
        "__all__ = ['QuantizableResNet', 'resnet18', 'resnet50',\n",
        "           'resnext101_32x8d']\n",
        "\n",
        "\n",
        "quant_model_urls = {\n",
        "    'resnet18_fbgemm':\n",
        "        'https://download.pytorch.org/models/quantized/resnet18_fbgemm_16fa66dd.pth',\n",
        "    'resnet50_fbgemm':\n",
        "        'https://download.pytorch.org/models/quantized/resnet50_fbgemm_bf931d71.pth',\n",
        "    'resnext101_32x8d_fbgemm':\n",
        "        'https://download.pytorch.org/models/quantized/resnext101_32x8_fbgemm_09835ccf.pth',\n",
        "}\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes, affine = affine_par)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes, affine = affine_par)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1,  dilation_ = 1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False) # change\n",
        "        self.bn1 = nn.BatchNorm2d(planes,affine = affine_par)\n",
        "        for i in self.bn1.parameters():\n",
        "            i.requires_grad = False\n",
        "        padding = 1\n",
        "        if dilation_ == 2:\n",
        "            padding = 2\n",
        "        elif dilation_ == 4:\n",
        "            padding = 4\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, # change\n",
        "                               padding=padding, bias=False, dilation = dilation_)\n",
        "        self.bn2 = nn.BatchNorm2d(planes,affine = affine_par)\n",
        "        for i in self.bn2.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4, affine = affine_par)\n",
        "        for i in self.bn3.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64,affine = affine_par)\n",
        "        for i in self.bn1.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True) # change\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation__ = 2)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1,dilation__ = 1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion or dilation__ == 2 or dilation__ == 4:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion,affine = affine_par),\n",
        "            )\n",
        "        for i in downsample._modules['1'].parameters():\n",
        "            i.requires_grad = False\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride,dilation_=dilation__, downsample = downsample ))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes,dilation_=dilation__))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        tmp_x = []\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        tmp_x.append(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        tmp_x.append(x)\n",
        "        x = self.layer2(x)\n",
        "        tmp_x.append(x)\n",
        "        x = self.layer3(x)\n",
        "        tmp_x.append(x)\n",
        "        x = self.layer4(x)\n",
        "        tmp_x.append(x)\n",
        "\n",
        "        return tmp_x\n",
        "\n",
        "\n",
        "class QuantizableBasicBlock(BasicBlock):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(QuantizableBasicBlock, self).__init__(*args, **kwargs)\n",
        "        self.add_relu = torch.nn.quantized.FloatFunctional()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.add_relu.add_relu(out, identity)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def fuse_model(self):\n",
        "        torch.quantization.fuse_modules(self, [['conv1', 'bn1', 'relu'],\n",
        "                                               ['conv2', 'bn2']], inplace=True)\n",
        "        if self.downsample:\n",
        "            torch.quantization.fuse_modules(self.downsample, ['0', '1'], inplace=True)\n",
        "\n",
        "\n",
        "class QuantizableBottleneck(Bottleneck):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(QuantizableBottleneck, self).__init__(*args, **kwargs)\n",
        "        self.skip_add_relu = nn.quantized.FloatFunctional()\n",
        "        self.relu1 = nn.ReLU(inplace=False)\n",
        "        self.relu2 = nn.ReLU(inplace=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out = self.skip_add_relu.add_relu(out, identity)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def fuse_model(self):\n",
        "        fuse_modules(self, [['conv1', 'bn1', 'relu1'],\n",
        "                            ['conv2', 'bn2', 'relu2'],\n",
        "                            ['conv3', 'bn3']], inplace=True)\n",
        "        if self.downsample:\n",
        "            torch.quantization.fuse_modules(self.downsample, ['0', '1'], inplace=True)\n",
        "\n",
        "\n",
        "class QuantizableResNet(ResNet):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(QuantizableResNet, self).__init__(*args, **kwargs)\n",
        "\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        # Ensure scriptability\n",
        "        #super(QuantizableResNet,self).forward(x)\n",
        "        # is not scriptable\n",
        "        #x = self._forward_impl(x)\n",
        "        x = self.dequant(x)\n",
        "        return x\n",
        "\n",
        "    def fuse_model(self):\n",
        "        r\"\"\"Fuse conv/bn/relu modules in resnet models\n",
        "        Fuse conv+bn+relu/ Conv+relu/conv+Bn modules to prepare for quantization.\n",
        "        Model is modified in place.  Note that this operation does not change numerics\n",
        "        and the model after modification is in floating point\n",
        "        \"\"\"\n",
        "\n",
        "        fuse_modules(self, ['conv1', 'bn1', 'relu'], inplace=True)\n",
        "        for m in self.modules():\n",
        "            if type(m) == QuantizableBottleneck or type(m) == QuantizableBasicBlock:\n",
        "                m.fuse_model()\n",
        "\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, quantize, **kwargs):\n",
        "    model = QuantizableResNet(block, layers, **kwargs)\n",
        "    _replace_relu(model)\n",
        "    if quantize:\n",
        "        # TODO use pretrained as a string to specify the backend\n",
        "        backend = 'fbgemm'\n",
        "        quantize_model(model, backend)\n",
        "    else:\n",
        "        assert pretrained in [True, False]\n",
        "\n",
        "    if pretrained:\n",
        "        if quantize:\n",
        "            model_url = quant_model_urls[arch + '_' + backend]\n",
        "        else:\n",
        "            model_url = model_urls[arch]\n",
        "\n",
        "        state_dict = load_state_dict_from_url(model_url,\n",
        "                                              progress=progress)\n",
        "\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "def resnet50(pretrained=False , progress=True, quantize=True, **kwargs):\n",
        "    r\"\"\"ResNet-50 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet50', QuantizableBottleneck, [3, 4, 6, 3], pretrained, progress,\n",
        "                   quantize, **kwargs)\n",
        "def resnet18(pretrained=False, progress=True, quantize=False, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', QuantizableBasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
        "                   quantize, **kwargs)\n",
        "    \n",
        "modelQ = resnet50(quantize=True)\n",
        "\n",
        "class ResNet_locate(nn.Module):\n",
        "    def __init__(self, block, layers):\n",
        "        super(ResNet_locate,self).__init__() #block, layers\n",
        "        self.resnet = QuantizableResNet(block, layers) # resnet50(quantize=True) #\n",
        "        self.in_planes = 512\n",
        "        self.out_planes = [512, 256, 256, 128]\n",
        "\n",
        "        self.ppms_pre = nn.Conv2d(2048, self.in_planes, 1, 1, bias=False)\n",
        "        ppms, infos = [], []\n",
        "        for ii in [1, 3, 5]:\n",
        "            ppms.append(nn.Sequential(nn.AdaptiveAvgPool2d(ii), nn.Conv2d(self.in_planes, self.in_planes, 1, 1, bias=False), nn.ReLU(inplace=True)))\n",
        "        self.ppms = nn.ModuleList(ppms)\n",
        "\n",
        "        self.ppm_cat = nn.Sequential(nn.Conv2d(self.in_planes * 4, self.in_planes, 3, 1, 1, bias=False), nn.ReLU(inplace=True))\n",
        "        for ii in self.out_planes:\n",
        "            infos.append(nn.Sequential(nn.Conv2d(self.in_planes, ii, 3, 1, 1, bias=False), nn.ReLU(inplace=True)))\n",
        "        self.infos = nn.ModuleList(infos)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def load_pretrained_model(self, model):\n",
        "        self.resnet.load_state_dict(model, strict=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_size = x.size()[2:]\n",
        "        xs = self.resnet(x)\n",
        "\n",
        "        xs_1 = self.ppms_pre(xs[-1])\n",
        "        xls = [xs_1]\n",
        "        for k in range(len(self.ppms)):\n",
        "            xls.append(F.interpolate(self.ppms[k](xs_1), xs_1.size()[2:], mode='bilinear', align_corners=True))\n",
        "        xls = self.ppm_cat(torch.cat(xls, dim=1))\n",
        "\n",
        "        infos = []\n",
        "        for k in range(len(self.infos)):\n",
        "            infos.append(self.infos[k](F.interpolate(xls, xs[len(self.infos) - 1 - k].size()[2:], mode='bilinear', align_corners=True)))\n",
        "\n",
        "        return xs, infos\n",
        "\n",
        "def resnet50_locate():\n",
        "    model = ResNet_locate(QuantizableBottleneck, [3, 4, 6, 3])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54M-lXo9gNtf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelQ.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjln9dS90QTy",
        "colab_type": "text"
      },
      "source": [
        "### Poolnet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etIDxI-cy10-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "#from .deeplab_resnet import resnet50_locate\n",
        "#from .vgg import vgg16_locate\n",
        "from torch.autograd import Variable\n",
        "\n",
        "config_vgg = {'convert': [[128,256,512,512,512],[64,128,256,512,512]], 'deep_pool': [[512, 512, 256, 128], [512, 256, 128, 128], [True, True, True, False], [True, True, True, False]], 'score': 128}  # no convert layer, no conv6\n",
        "\n",
        "config_resnet = {'convert': [[64,256,512,1024,2048],[128,256,256,512,512]], 'deep_pool': [[512, 512, 256, 256, 128], [512, 256, 256, 128, 128], [False, True, True, True, False], [True, True, True, True, False]], 'score': 128}\n",
        "\n",
        "class ConvertLayer(nn.Module):\n",
        "    def __init__(self, list_k):\n",
        "        super(ConvertLayer, self).__init__()\n",
        "        up = []\n",
        "        for i in range(len(list_k[0])):\n",
        "            up.append(nn.Sequential(nn.Conv2d(list_k[0][i], list_k[1][i], 1, 1, bias=False), nn.ReLU(inplace=True)))\n",
        "        self.convert0 = nn.ModuleList(up)\n",
        "\n",
        "    def forward(self, list_x):\n",
        "        resl = []\n",
        "        for i in range(len(list_x)):\n",
        "            resl.append(self.convert0[i](list_x[i]))\n",
        "        return resl\n",
        "\n",
        "class DeepPoolLayer(nn.Module):\n",
        "    def __init__(self, k, k_out, need_x2, need_fuse):\n",
        "        super(DeepPoolLayer, self).__init__()\n",
        "        self.pools_sizes = [2,4,8]\n",
        "        self.need_x2 = need_x2\n",
        "        self.need_fuse = need_fuse\n",
        "        pools, convs = [],[]\n",
        "        for i in self.pools_sizes:\n",
        "            pools.append(nn.AvgPool2d(kernel_size=i, stride=i))\n",
        "            convs.append(nn.Conv2d(k, k, 3, 1, 1, bias=False))\n",
        "        self.pools = nn.ModuleList(pools)\n",
        "        self.convs = nn.ModuleList(convs)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv_sum = nn.Conv2d(k, k_out, 3, 1, 1, bias=False)\n",
        "        if self.need_fuse:\n",
        "            self.conv_sum_c = nn.Conv2d(k_out, k_out, 3, 1, 1, bias=False)\n",
        "\n",
        "    def forward(self, x, x2=None, x3=None):\n",
        "        x_size = x.size()\n",
        "        resl = x\n",
        "        for i in range(len(self.pools_sizes)):\n",
        "            y = self.convs[i](self.pools[i](x))\n",
        "            resl = torch.add(resl, F.interpolate(y, x_size[2:], mode='bilinear', align_corners=True))\n",
        "        resl = self.relu(resl)\n",
        "        if self.need_x2:\n",
        "            resl = F.interpolate(resl, x2.size()[2:], mode='bilinear', align_corners=True)\n",
        "        resl = self.conv_sum(resl)\n",
        "        if self.need_fuse:\n",
        "            resl = self.conv_sum_c(torch.add(torch.add(resl, x2), x3))\n",
        "        return resl\n",
        "\n",
        "class ScoreLayer(nn.Module):\n",
        "    def __init__(self, k):\n",
        "        super(ScoreLayer, self).__init__()\n",
        "        self.score = nn.Conv2d(k ,1, 1, 1)\n",
        "\n",
        "    def forward(self, x, x_size=None):\n",
        "        x = self.score(x)\n",
        "        if x_size is not None:\n",
        "            x = F.interpolate(x, x_size[2:], mode='bilinear', align_corners=True)\n",
        "        return x\n",
        "\n",
        "def extra_layer(base_model_cfg, vgg):\n",
        "    if base_model_cfg == 'vgg':\n",
        "        config = config_vgg\n",
        "    elif base_model_cfg == 'resnet':\n",
        "        config = config_resnet\n",
        "    convert_layers, deep_pool_layers, score_layers = [], [], []\n",
        "    convert_layers = ConvertLayer(config['convert'])\n",
        "\n",
        "    for i in range(len(config['deep_pool'][0])):\n",
        "        deep_pool_layers += [DeepPoolLayer(config['deep_pool'][0][i], config['deep_pool'][1][i], config['deep_pool'][2][i], config['deep_pool'][3][i])]\n",
        "\n",
        "    score_layers = ScoreLayer(config['score'])\n",
        "\n",
        "    return vgg, convert_layers, deep_pool_layers, score_layers\n",
        "\n",
        "\n",
        "class PoolNet(nn.Module):\n",
        "    def __init__(self, base_model_cfg, base, convert_layers, deep_pool_layers, score_layers):\n",
        "        super(PoolNet, self).__init__()\n",
        "        self.base_model_cfg = base_model_cfg\n",
        "        self.base = base\n",
        "        self.deep_pool = nn.ModuleList(deep_pool_layers)\n",
        "        self.score = score_layers\n",
        "        if self.base_model_cfg == 'resnet':\n",
        "            self.convert = convert_layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_size = x.size()\n",
        "        conv2merge, infos = self.base(x)\n",
        "        if self.base_model_cfg == 'resnet':\n",
        "            conv2merge = self.convert(conv2merge)\n",
        "        conv2merge = conv2merge[::-1]\n",
        "\n",
        "        edge_merge = []\n",
        "        merge = self.deep_pool[0](conv2merge[0], conv2merge[1], infos[0])\n",
        "        for k in range(1, len(conv2merge)-1):\n",
        "            merge = self.deep_pool[k](merge, conv2merge[k+1], infos[k])\n",
        "\n",
        "        merge = self.deep_pool[-1](merge)\n",
        "        merge = self.score(merge, x_size)\n",
        "        return merge\n",
        "\n",
        "def build_model(base_model_cfg='vgg'):\n",
        "    if base_model_cfg == 'vgg':\n",
        "        return PoolNet(base_model_cfg, *extra_layer(base_model_cfg, vgg16_locate()))\n",
        "    elif base_model_cfg == 'resnet':\n",
        "        return PoolNet(base_model_cfg, *extra_layer(base_model_cfg, resnet50_locate()))\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(0, 0.01)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfOe6lsBs8b2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PNModel = build_model('resnet')\n",
        "PNModel.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QDTVO2T_l0l",
        "colab_type": "text"
      },
      "source": [
        "### ResNet 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbiqbSMR_zdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "affine_par = True\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes, affine = affine_par)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes, affine = affine_par)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1,  dilation_ = 1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False) # change\n",
        "        self.bn1 = nn.BatchNorm2d(planes,affine = affine_par)\n",
        "        for i in self.bn1.parameters():\n",
        "            i.requires_grad = False\n",
        "        padding = 1\n",
        "        if dilation_ == 2:\n",
        "            padding = 2\n",
        "        elif dilation_ == 4:\n",
        "            padding = 4\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, # change\n",
        "                               padding=padding, bias=False, dilation = dilation_)\n",
        "        self.bn2 = nn.BatchNorm2d(planes,affine = affine_par)\n",
        "        for i in self.bn2.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4, affine = affine_par)\n",
        "        for i in self.bn3.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64,affine = affine_par)\n",
        "        for i in self.bn1.parameters():\n",
        "            i.requires_grad = False\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True) # change\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation__ = 2)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1,dilation__ = 1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion or dilation__ == 2 or dilation__ == 4:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion,affine = affine_par),\n",
        "            )\n",
        "        for i in downsample._modules['1'].parameters():\n",
        "            i.requires_grad = False\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride,dilation_=dilation__, downsample = downsample ))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes,dilation_=dilation__))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        tmp_x = []\n",
        "        x = self.conv1(x)\n",
        "       \n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        tmp_x.append(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        tmp_x.append(x)\n",
        "        x = self.layer2(x)\n",
        "        tmp_x.append(x)\n",
        "        x = self.layer3(x)\n",
        "        tmp_x.append(x)\n",
        "        x = self.layer4(x)\n",
        "        tmp_x.append(x)\n",
        "\n",
        "        return tmp_x\n",
        "\n",
        "\n",
        "class ResNet_locate(nn.Module):\n",
        "    def __init__(self, block, layers):\n",
        "        super(ResNet_locate,self).__init__()\n",
        "        self.resnet = ResNet(block, layers)\n",
        "        self.in_planes = 512\n",
        "        self.out_planes = [512, 256, 256, 128]\n",
        "\n",
        "        self.ppms_pre = nn.Conv2d(2048, self.in_planes, 1, 1, bias=False)\n",
        "        ppms, infos = [], []\n",
        "        for ii in [1, 3, 5]:\n",
        "            ppms.append(nn.Sequential(nn.AdaptiveAvgPool2d(ii), nn.Conv2d(self.in_planes, self.in_planes, 1, 1, bias=False), nn.ReLU(inplace=True)))\n",
        "        self.ppms = nn.ModuleList(ppms)\n",
        "\n",
        "        self.ppm_cat = nn.Sequential(nn.Conv2d(self.in_planes * 4, self.in_planes, 3, 1, 1, bias=False), nn.ReLU(inplace=True))\n",
        "        for ii in self.out_planes:\n",
        "            infos.append(nn.Sequential(nn.Conv2d(self.in_planes, ii, 3, 1, 1, bias=False), nn.ReLU(inplace=True)))\n",
        "        self.infos = nn.ModuleList(infos)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def load_pretrained_model(self, model):\n",
        "        self.resnet.load_state_dict(model, strict=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_size = x.size()[2:]\n",
        "        xs = self.resnet(x)\n",
        "\n",
        "        xs_1 = self.ppms_pre(xs[-1])\n",
        "        xls = [xs_1]\n",
        "        for k in range(len(self.ppms)):\n",
        "            xls.append(F.interpolate(self.ppms[k](xs_1), xs_1.size()[2:], mode='bilinear', align_corners=True))\n",
        "        xls = self.ppm_cat(torch.cat(xls, dim=1))\n",
        "\n",
        "        infos = []\n",
        "        for k in range(len(self.infos)):\n",
        "            infos.append(self.infos[k](F.interpolate(xls, xs[len(self.infos) - 1 - k].size()[2:], mode='bilinear', align_corners=True)))\n",
        "\n",
        "        return xs, infos\n",
        "\n",
        "def resnet50_locate():\n",
        "    model = ResNet_locate(Bottleneck, [3, 4, 6, 3])\n",
        "    return model"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lo-YiC3_u7J",
        "colab_type": "text"
      },
      "source": [
        "### PoolNet 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YPzsHC5_6al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import init\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "#from .deeplab_resnet import resnet50_locate\n",
        "#from .vgg import vgg16_locate\n",
        "\n",
        "\n",
        "config_vgg = {'convert': [[128,256,512,512,512],[64,128,256,512,512]], 'deep_pool': [[512, 512, 256, 128], [512, 256, 128, 128], [True, True, True, False], [True, True, True, False]], 'score': 128}  # no convert layer, no conv6\n",
        "\n",
        "config_resnet = {'convert': [[64,256,512,1024,2048],[128,256,256,512,512]], 'deep_pool': [[512, 512, 256, 256, 128], [512, 256, 256, 128, 128], [False, True, True, True, False], [True, True, True, True, False]], 'score': 128}\n",
        "\n",
        "class ConvertLayer(nn.Module):\n",
        "    def __init__(self, list_k):\n",
        "        super(ConvertLayer, self).__init__()\n",
        "        up = []\n",
        "        for i in range(len(list_k[0])):\n",
        "            up.append(nn.Sequential(nn.Conv2d(list_k[0][i], list_k[1][i], 1, 1, bias=False), nn.ReLU(inplace=True)))\n",
        "        self.convert0 = nn.ModuleList(up)\n",
        "\n",
        "    def forward(self, list_x):\n",
        "        resl = []\n",
        "        for i in range(len(list_x)):\n",
        "            resl.append(self.convert0[i](list_x[i]))\n",
        "        return resl\n",
        "\n",
        "class DeepPoolLayer(nn.Module):\n",
        "    def __init__(self, k, k_out, need_x2, need_fuse):\n",
        "        super(DeepPoolLayer, self).__init__()\n",
        "        self.pools_sizes = [2,4,8]\n",
        "        self.need_x2 = need_x2\n",
        "        self.need_fuse = need_fuse\n",
        "        pools, convs = [],[]\n",
        "        for i in self.pools_sizes:\n",
        "            pools.append(nn.AvgPool2d(kernel_size=i, stride=i))\n",
        "            convs.append(nn.Conv2d(k, k, 3, 1, 1, bias=False))\n",
        "        self.pools = nn.ModuleList(pools)\n",
        "        self.convs = nn.ModuleList(convs)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv_sum = nn.Conv2d(k, k_out, 3, 1, 1, bias=False)\n",
        "        if self.need_fuse:\n",
        "            self.conv_sum_c = nn.Conv2d(k_out, k_out, 3, 1, 1, bias=False)\n",
        "\n",
        "    def forward(self, x, x2=None, x3=None):\n",
        "        x_size = x.size()\n",
        "        resl = x\n",
        "        for i in range(len(self.pools_sizes)):\n",
        "            y = self.convs[i](self.pools[i](x))\n",
        "            resl = torch.add(resl, F.interpolate(y, x_size[2:], mode='bilinear', align_corners=True))\n",
        "        resl = self.relu(resl)\n",
        "        if self.need_x2:\n",
        "            resl = F.interpolate(resl, x2.size()[2:], mode='bilinear', align_corners=True)\n",
        "        resl = self.conv_sum(resl)\n",
        "        if self.need_fuse:\n",
        "            resl = self.conv_sum_c(torch.add(torch.add(resl, x2), x3))\n",
        "        return resl\n",
        "\n",
        "class ScoreLayer(nn.Module):\n",
        "    def __init__(self, k):\n",
        "        super(ScoreLayer, self).__init__()\n",
        "        self.score = nn.Conv2d(k ,1, 1, 1)\n",
        "\n",
        "    def forward(self, x, x_size=None):\n",
        "        x = self.score(x)\n",
        "        if x_size is not None:\n",
        "            x = F.interpolate(x, x_size[2:], mode='bilinear', align_corners=True)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PoolNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PoolNet, self).__init__()\n",
        "        config = config_resnet\n",
        "        convert_layers, deep_pool_layers, score_layers = [], [], []\n",
        "        convert_layers = ConvertLayer(config['convert'])\n",
        "        test = 15\n",
        "        self.test = test\n",
        "        \n",
        "        for i in range(len(config['deep_pool'][0])):\n",
        "            deep_pool_layers += [DeepPoolLayer(config['deep_pool'][0][i], config['deep_pool'][1][i], config['deep_pool'][2][i], config['deep_pool'][3][i])]\n",
        "\n",
        "        score_layers = ScoreLayer(config['score'])        \n",
        "\n",
        "        self.base_model_cfg = 'resnet'\n",
        "        self.base = ResNet_locate(Bottleneck, [3, 4, 6, 3])\n",
        "        self.deep_pool = nn.ModuleList(deep_pool_layers)\n",
        "        self.score = score_layers\n",
        "        if self.base_model_cfg == 'resnet':\n",
        "            self.convert = convert_layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_size = x.size()\n",
        "        conv2merge, infos = self.base(x)\n",
        "        if self.base_model_cfg == 'resnet':\n",
        "            conv2merge = self.convert(conv2merge)\n",
        "        conv2merge = conv2merge[::-1]\n",
        "\n",
        "        edge_merge = []\n",
        "        merge = self.deep_pool[0](conv2merge[0], conv2merge[1], infos[0])\n",
        "        for k in range(1, len(conv2merge)-1):\n",
        "            merge = self.deep_pool[k](merge, conv2merge[k+1], infos[k])\n",
        "\n",
        "        merge = self.deep_pool[-1](merge)\n",
        "        merge = self.score(merge, x_size)\n",
        "        return merge\n",
        "\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(0, 0.01)\n",
        "        if m.bias is not None:\n",
        "            m.bias.data.zero_()"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw3KiRFfM2CY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ab78e88e-2bd8-48a6-cd5f-aa7583472ceb"
      },
      "source": [
        "PNModel1 = PoolNet()\n",
        "PNModel1.eval()\n",
        "print(type(PNModel1))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class '__main__.PoolNet'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLluxc7OhgSd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d343434-07c6-4321-ea18-7dda86cab160"
      },
      "source": [
        "model = resnet50_locate()\n",
        "print(model)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet_locate(\n",
            "  (resnet): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            "  )\n",
            "  (ppms_pre): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (ppms): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): AdaptiveAvgPool2d(output_size=1)\n",
            "      (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): AdaptiveAvgPool2d(output_size=3)\n",
            "      (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): AdaptiveAvgPool2d(output_size=5)\n",
            "      (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (ppm_cat): Sequential(\n",
            "    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (1): ReLU(inplace=True)\n",
            "  )\n",
            "  (infos): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): ReLU(inplace=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "697BTD6QAuNs",
        "colab_type": "text"
      },
      "source": [
        "### Quant class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRFYyXLhAtdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision.models.resnet import Bottleneck, BasicBlock, ResNet, model_urls\n",
        "import torch.nn as nn\n",
        "from torchvision.models.utils import load_state_dict_from_url\n",
        "from torch.quantization import QuantStub, DeQuantStub, fuse_modules\n",
        "from torch._jit_internal import Optional\n",
        "from torchvision.models.quantization.utils import _replace_relu, quantize_model\n",
        "\n",
        "__all__ = ['QuantizableResNet', 'resnet18', 'resnet50',\n",
        "           'resnext101_32x8d']\n",
        "\n",
        "\n",
        "quant_model_urls = {\n",
        "    'resnet18_fbgemm':\n",
        "        'https://download.pytorch.org/models/quantized/resnet18_fbgemm_16fa66dd.pth',\n",
        "    'resnet50_fbgemm':\n",
        "        'https://download.pytorch.org/models/quantized/resnet50_fbgemm_bf931d71.pth',\n",
        "    'resnext101_32x8d_fbgemm':\n",
        "        'https://download.pytorch.org/models/quantized/resnext101_32x8_fbgemm_09835ccf.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class QuantizableBasicBlock(BasicBlock):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(QuantizableBasicBlock, self).__init__(*args, **kwargs)\n",
        "        self.add_relu = torch.nn.quantized.FloatFunctional()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.add_relu.add_relu(out, identity)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def fuse_model(self):\n",
        "        torch.quantization.fuse_modules(self, [['conv1', 'bn1', 'relu'],\n",
        "                                               ['conv2', 'bn2']], inplace=True)\n",
        "        if self.downsample:\n",
        "            torch.quantization.fuse_modules(self.downsample, ['0', '1'], inplace=True)\n",
        "\n",
        "\n",
        "class QuantizableBottleneck(Bottleneck):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(QuantizableBottleneck, self).__init__(*args, **kwargs)\n",
        "        self.skip_add_relu = nn.quantized.FloatFunctional()\n",
        "        self.relu1 = nn.ReLU(inplace=False)\n",
        "        self.relu2 = nn.ReLU(inplace=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out = self.skip_add_relu.add_relu(out, identity)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def fuse_model(self):\n",
        "        fuse_modules(self, [['conv1', 'bn1', 'relu1'],\n",
        "                            ['conv2', 'bn2', 'relu2'],\n",
        "                            ['conv3', 'bn3']], inplace=True)\n",
        "        if self.downsample:\n",
        "            torch.quantization.fuse_modules(self.downsample, ['0', '1'], inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "class QuantizableResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(QuantizableResNet, self).__init__() #*args, **kwargs\n",
        "\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "        pool = PoolNet()\n",
        "        print(pool.test)\n",
        "\n",
        "        rl = ResNet_locate \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        # Ensure scriptability\n",
        "        # super(QuantizableResNet,self).forward(x)\n",
        "        # is not scriptable\n",
        "        x = self._forward_impl(x)\n",
        "        x = self.dequant(x)\n",
        "        return x\n",
        "\n",
        "    def fuse_model(self):\n",
        "        r\"\"\"Fuse conv/bn/relu modules in resnet models\n",
        "        Fuse conv+bn+relu/ Conv+relu/conv+Bn modules to prepare for quantization.\n",
        "        Model is modified in place.  Note that this operation does not change numerics\n",
        "        and the model after modification is in floating point\n",
        "        \"\"\"\n",
        "\n",
        "        fuse_modules(self, ['conv1', 'bn1', 'relu'], inplace=True)\n",
        "        for m in self.modules():\n",
        "            if type(m) == QuantizableBottleneck or type(m) == QuantizableBasicBlock:\n",
        "                m.fuse_model()\n",
        "\n",
        "\n",
        "def _resnet(arch, block, layers, pretrained, progress, quantize, **kwargs):\n",
        "    model = QuantizableResNet(block, layers, **kwargs)\n",
        "    _replace_relu(model)\n",
        "    if quantize:\n",
        "        # TODO use pretrained as a string to specify the backend\n",
        "        backend = 'fbgemm'\n",
        "        quantize_model(model, backend)\n",
        "    else:\n",
        "        assert pretrained in [True, False]\n",
        "\n",
        "    if pretrained:\n",
        "        if quantize:\n",
        "            model_url = quant_model_urls[arch + '_' + backend]\n",
        "        else:\n",
        "            model_url = model_urls[arch]\n",
        "\n",
        "        state_dict = load_state_dict_from_url(model_url,\n",
        "                                              progress=progress)\n",
        "\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet18(pretrained=False, progress=True, quantize=False, **kwargs):\n",
        "    r\"\"\"ResNet-18 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet18', QuantizableBasicBlock, [2, 2, 2, 2], pretrained, progress,\n",
        "                   quantize, **kwargs)\n",
        "\n",
        "\n",
        "def resnet50(pretrained=True, progress=True, quantize=False, **kwargs):\n",
        "    r\"\"\"ResNet-50 model from\n",
        "    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    return _resnet('resnet50', QuantizableBottleneck, [3, 4, 6, 3], pretrained, progress,\n",
        "                   quantize, **kwargs)\n",
        "\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U2jiWDy0XPe",
        "colab_type": "text"
      },
      "source": [
        "## Quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQDPbZ81xbMq",
        "colab_type": "text"
      },
      "source": [
        "### Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfzKCwgxxVm8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "afdea6d8-fac9-48a9-a730-34b2a6acfb7c"
      },
      "source": [
        "import torchvision.models.quantization as models\n",
        "#qat_model = models.resnet18(pretrained=False, progress=True, quantize=False)\n",
        " \n",
        "qat_model =  resnet50()\n",
        "    \n",
        "_replace_relu(qat_model)\n",
        "backend = 'fbgemm'\n",
        "quantize_model(qat_model, backend)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-35dc78126299>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#qat_model = models.resnet18(pretrained=False, progress=True, quantize=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mqat_model\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0m_replace_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqat_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-072db8b0002c>\u001b[0m in \u001b[0;36mresnet50\u001b[0;34m(pretrained, progress, quantize, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \"\"\"\n\u001b[1;32m    162\u001b[0m     return _resnet('resnet50', QuantizableBottleneck, [3, 4, 6, 3], pretrained, progress,\n\u001b[0;32m--> 163\u001b[0;31m                    quantize, **kwargs)\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-072db8b0002c>\u001b[0m in \u001b[0;36m_resnet\u001b[0;34m(arch, block, layers, pretrained, progress, quantize, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               progress=progress)\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1045\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for QuantizableResNet:\n\tUnexpected key(s) in state_dict: \"conv1.weight\", \"bn1.running_mean\", \"bn1.running_var\", \"bn1.weight\", \"bn1.bias\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.conv3.weight\", \"layer1.0.bn3.running_mean\", \"layer1.0.bn3.running_var\", \"layer1.0.bn3.weight\", \"layer1.0.bn3.bias\", \"layer1.0.downsample.0.weight\", \"layer1.0.downsample.1.running_mean\", \"layer1.0.downsample.1.running_var\", \"layer1.0.downsample.1.weight\", \"layer1.0.downsample.1.bias\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.conv3.weight\", \"layer1.1.bn3.running_mean\", \"layer1.1.bn3.running_var\", \"layer1.1.bn3.weight\", \"layer1.1.bn3.bias\", \"layer1.2.conv1.weight\", \"layer1.2.bn1.running_mean\", \"layer1.2.bn1.running_var\", \"layer1.2.bn1.weight\", \"layer1.2.bn1.bias\", \"layer1.2.conv2.weight\", \"layer1.2.bn2.running_mean\", \"layer1.2.bn2.running_var\", \"layer1.2.bn2.weight\", \"layer1.2.bn2.bias\", \"layer1.2.conv3.weight\", \"layer1.2.bn3.running_mean\", \"layer1.2.bn3.running_var\", \"layer1.2.bn3.weight\", \"layer1.2.bn3.bias\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var..."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OoXZOUxJiRP",
        "colab_type": "text"
      },
      "source": [
        "### Quantization-aware training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR33mE3ZJPoo",
        "colab_type": "text"
      },
      "source": [
        "Changing just this quantization configuration method resulted in an increase\n",
        "of the accuracy to over 76%! Still, this is 1-2% worse than the baseline of 78% achieved above.\n",
        "So lets try quantization aware training.\n",
        "\n",
        "5. Quantization-aware training\n",
        "------------------------------\n",
        "\n",
        "Quantization-aware training (QAT) is the quantization method that typically results in the highest accuracy.\n",
        "With QAT, all weights and activations are “fake quantized” during both the forward and backward passes of\n",
        "training: that is, float values are rounded to mimic int8 values, but all computations are still done with\n",
        "floating point numbers. Thus, all the weight adjustments during training are made while “aware” of the fact\n",
        "that the model will ultimately be quantized; after quantizing, therefore, this method will usually yield\n",
        "higher accuracy than either dynamic quantization or post-training static quantization.\n",
        "\n",
        "The overall workflow for actually performing QAT is very similar to before:\n",
        "\n",
        "- We can use the same model as before: there is no additional preparation needed for quantization-aware\n",
        "  training.\n",
        "- We need to use a ``qconfig`` specifying what kind of fake-quantization is to be inserted after weights\n",
        "  and activations, instead of specifying observers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1UXLWEtJPov",
        "colab_type": "text"
      },
      "source": [
        "We fuse modules as before\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-kFqt5iJPow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "c5f5f4c5-5787-44eb-e684-a6192780799b"
      },
      "source": [
        "qat_model.fuse_model()\n",
        "\n",
        "optimizer = torch.optim.SGD(qat_model.parameters(), lr = 0.0001)\n",
        "qat_model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-7b95e7c4c795>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuse_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mqat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_qat_qconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fbgemm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-c66fc721c585>\u001b[0m in \u001b[0;36mfuse_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \"\"\"\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mfuse_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'conv1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bn1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mQuantizableBottleneck\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mQuantizableBasicBlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/quantization/fuse_modules.py\u001b[0m in \u001b[0;36mfuse_modules\u001b[0;34m(model, modules_to_fuse, inplace, fuser_func)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_element\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodule_element\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules_to_fuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# Handle case of modules_to_fuse being a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0m_fuse_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules_to_fuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuser_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# Handle case of modules_to_fuse being a list of lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/quantization/fuse_modules.py\u001b[0m in \u001b[0;36m_fuse_modules\u001b[0;34m(model, modules_to_fuse, fuser_func)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;31m# Fuse list of modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mnew_mod_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuser_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;31m# Replace original module list with fused module list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/quantization/fuse_modules.py\u001b[0m in \u001b[0;36mfuse_known_modules\u001b[0;34m(mod_list)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mfuser_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOP_LIST_TO_FUSER_METHOD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfuser_method\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot fuse modules: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0mnew_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mnew_mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuser_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmod_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Cannot fuse modules: (<class 'torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d'>, <class 'torch.nn.modules.linear.Identity'>, <class 'torch.nn.modules.linear.Identity'>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-fW0pWuit9j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a76da3ef-ef48-4838-b03b-3d838199e738"
      },
      "source": [
        "qat_model.eval()\n",
        "#torch.save(qat_model.state_dict(), 'Resnet_locate_quant.pth')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet_locate(\n",
              "  (resnet): QuantizableResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU()\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
              "    (layer1): Sequential(\n",
              "      (0): QuantizableBottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (skip_add_relu): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "        (relu1): ReLU()\n",
              "        (relu2): ReLU()\n",
              "      )\n",
              "      (1): QuantizableBottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (skip_add_relu): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "        (relu1): ReLU()\n",
              "        (relu2): ReLU()\n",
              "      )\n",
              "      (2): QuantizableBottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (skip_add_relu): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "        (relu1): ReLU()\n",
              "        (relu2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): QuantizableBottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (skip_add_relu): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "        (relu1): ReLU()\n",
              "        (relu2): ReLU()\n",
              "      )\n",
              "      (1): QuantizableBottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (skip_add_relu): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "        (relu1): ReLU()\n",
              "        (relu2): ReLU()\n",
              "      )\n",
              "      (2): QuantizableBottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (skip_add_relu): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "        (relu1): ReLU()\n",
              "        (relu2): ReLU()\n",
              "      )\n",
              "      (3): QuantizableBottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (skip_add_relu): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "        (relu1): ReLU()\n",
              "        (relu2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): QuantizableBottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (skip_add_relu): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "        (relu1): ReLU()\n",
              "        (relu2): ReLU()\n",
              "      )\n",
              "      (1): QuantizableBottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (skip_add_relu): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "        (relu1): ReLU()\n",
              "        (relu2): ReLU()\n",
              "      )\n",
              "      (2): QuantizableBottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (skip_add_relu): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "        (relu1): ReLU()\n",
              "        (relu2): ReLU()\n",
              "      )\n",
              "      (3): QuantizableBottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (skip_add_relu): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "        (relu1): ReLU()\n",
              "        (relu2): ReLU()\n",
              "      )\n",
              "      (4): QuantizableBottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (skip_add_relu): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "        (relu1): ReLU()\n",
              "        (relu2): ReLU()\n",
              "      )\n",
              "      (5): QuantizableBottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (skip_add_relu): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "        (relu1): ReLU()\n",
              "        (relu2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): QuantizableBottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (skip_add_relu): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "        (relu1): ReLU()\n",
              "        (relu2): ReLU()\n",
              "      )\n",
              "      (1): QuantizableBottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (skip_add_relu): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "        (relu1): ReLU()\n",
              "        (relu2): ReLU()\n",
              "      )\n",
              "      (2): QuantizableBottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU()\n",
              "        (skip_add_relu): FloatFunctional(\n",
              "          (activation_post_process): Identity()\n",
              "        )\n",
              "        (relu1): ReLU()\n",
              "        (relu2): ReLU()\n",
              "      )\n",
              "    )\n",
              "    (quant): QuantStub()\n",
              "    (dequant): DeQuantStub()\n",
              "  )\n",
              "  (ppms_pre): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (ppms): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (0): AdaptiveAvgPool2d(output_size=1)\n",
              "      (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (2): ReLU()\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): AdaptiveAvgPool2d(output_size=3)\n",
              "      (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (2): ReLU()\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): AdaptiveAvgPool2d(output_size=5)\n",
              "      (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (2): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (ppm_cat): Sequential(\n",
              "    (0): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (1): ReLU()\n",
              "  )\n",
              "  (infos): ModuleList(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jISoGH-7xFiS",
        "colab_type": "text"
      },
      "source": [
        "We first define a training function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G09SD59JPop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_one_epoch(model, criterion, optimizer, data_loader, device, ntrain_batches):\n",
        "    model.train()\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    avgloss = AverageMeter('Loss', '1.5f')\n",
        "\n",
        "    cnt = 0\n",
        "    for image, target in data_loader:\n",
        "        start_time = time.time()\n",
        "        print('.', end = '')\n",
        "        cnt += 1\n",
        "        image, target = image.to(device), target.to(device)\n",
        "        output = model(image)\n",
        "        loss = criterion(output, target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        top1.update(acc1[0], image.size(0))\n",
        "        top5.update(acc5[0], image.size(0))\n",
        "        avgloss.update(loss, image.size(0))\n",
        "        if cnt >= ntrain_batches:\n",
        "            print('Loss', avgloss.avg)\n",
        "\n",
        "            print('Training: * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
        "                  .format(top1=top1, top5=top5))\n",
        "            return\n",
        "\n",
        "    print('Full imagenet train set:  * Acc@1 {top1.global_avg:.3f} Acc@5 {top5.global_avg:.3f}'\n",
        "          .format(top1=top1, top5=top5))\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKe-OiC6JPo2",
        "colab_type": "text"
      },
      "source": [
        "Finally, ``prepare_qat`` performs the \"fake quantization\", preparing the model for quantization-aware\n",
        "training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VhHYiuKJPo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.quantization.prepare_qat(qat_model, inplace=True)\n",
        "#print('Inverted Residual Block: After preparation for QAT, note fake-quantization modules \\n',qat_model.features[1].conv)\n",
        "torch.save(qat_model.state_dict(), 'Resnet_locate_quant1.pth')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAh0tdBUS_W-",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFErx9LqJPo-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "221ab8d8-34d6-4c6a-b5c1-26007c2d9539"
      },
      "source": [
        "num_train_batches = 20\n",
        "num_eval_batches = 10\n",
        "\n",
        "# Train and check accuracy after each epoch\n",
        "for nepoch in range(8):\n",
        "    train_one_epoch(qat_model, criterion, optimizer, data_loader, torch.device('cpu'), num_train_batches)\n",
        "    if nepoch > 3:\n",
        "        # Freeze quantizer parameters\n",
        "        qat_model.apply(torch.quantization.disable_observer)\n",
        "    if nepoch > 2:\n",
        "        # Freeze batch norm mean and variance estimates\n",
        "        qat_model.apply(torch.nn.intrinsic.qat.freeze_bn_stats)\n",
        "\n",
        "    # Check the accuracy after each epoch\n",
        "    quantized_model = torch.quantization.convert(qat_model.eval(), inplace=False)\n",
        "    quantized_model.eval()\n",
        "    top1, top5 = evaluate(quantized_model,criterion, data_loader_test, neval_batches=num_eval_batches)\n",
        "    print('Epoch %d :Evaluation accuracy on %d images, %2.2f'%(nepoch, num_eval_batches * eval_batch_size, top1.avg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "."
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-5746dd2c9d73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train and check accuracy after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqat_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_train_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Freeze quantizer parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-083f64f25ab9>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, criterion, optimizer, data_loader, device, ntrain_batches)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-92c9f342ab1e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mxs_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mppms_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0mxls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxs_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mppms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/qat/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         return self.activation_post_process(\n\u001b[0;32m---> 36\u001b[0;31m             self._conv_forward(input, self.weight_fake_quant(self.weight)))\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    415\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 416\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [512, 2048, 1, 1], but got 3-dimensional input of size [3, 224, 224] instead"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ahzRJqRJPpE",
        "colab_type": "text"
      },
      "source": [
        "Here, we just perform quantization-aware training for a small number of epochs. Nevertheless,\n",
        "quantization-aware training yields an accuracy of over 71% on the entire imagenet dataset,\n",
        "which is close to the floating point accuracy of 71.9%.\n",
        "\n",
        "More on quantization-aware training:\n",
        "\n",
        "- QAT is a super-set of post training quant techniques that allows for more debugging.\n",
        "  For example, we can analyze if the accuracy of the model is limited by weight or activation\n",
        "  quantization.\n",
        "- We can also simulate the accuracy of a quantized model in floating point since\n",
        "  we are using fake-quantization to model the numerics of actual quantized arithmetic.\n",
        "- We can mimic post training quantization easily too.\n",
        "\n",
        "Speedup from quantization\n",
        "^^^^^^^^^^^^^^^^^^^^^^^^^\n",
        "\n",
        "Finally, let's confirm something we alluded to above: do our quantized models actually perform inference\n",
        "faster? Let's test:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOL7u2GfTTQM",
        "colab_type": "text"
      },
      "source": [
        "### Test Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo9Cy97KJPpF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "29a950b4-0974-4a89-9538-d7bf0c11b09c"
      },
      "source": [
        "torch.jit.save(torch.jit.script(quantized_model), saved_model_dir + scripted_quantized_model_file)\n",
        "\n",
        "def run_benchmark(model_file, img_loader):\n",
        "    elapsed = 0\n",
        "    model = torch.jit.load(model_file)\n",
        "    model.eval()\n",
        "    num_batches = 5\n",
        "    # Run the scripted model on a few batches of images\n",
        "    for i, (images, target) in enumerate(img_loader):\n",
        "        if i < num_batches:\n",
        "            start = time.time()\n",
        "            output = model(images)\n",
        "            end = time.time()\n",
        "            elapsed = elapsed + (end-start)\n",
        "        else:\n",
        "            break\n",
        "    num_images = images.size()[0] * num_batches\n",
        "\n",
        "    print('Elapsed time: %3.0f ms' % (elapsed/num_images*1000))\n",
        "    return elapsed\n",
        "\n",
        "#run_benchmark(saved_model_dir + scripted_float_model_file, data_loader_test)\n",
        "\n",
        "run_benchmark(saved_model_dir + scripted_quantized_model_file, data_loader_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elapsed time:  31 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.700316667556763"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}